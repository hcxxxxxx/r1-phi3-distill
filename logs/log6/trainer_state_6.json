{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.99989330298396,
  "eval_steps": 500,
  "global_step": 21087,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021339403208023616,
      "grad_norm": 1.5035400390625,
      "learning_rate": 7.112375533428166e-06,
      "loss": 8.189,
      "step": 150
    },
    {
      "epoch": 0.04267880641604723,
      "grad_norm": 3.6030235290527344,
      "learning_rate": 1.4224751066856332e-05,
      "loss": 6.7093,
      "step": 300
    },
    {
      "epoch": 0.06401820962407084,
      "grad_norm": 0.612079381942749,
      "learning_rate": 2.1337126600284495e-05,
      "loss": 3.9591,
      "step": 450
    },
    {
      "epoch": 0.08535761283209446,
      "grad_norm": 0.6478579640388489,
      "learning_rate": 2.8449502133712663e-05,
      "loss": 3.6995,
      "step": 600
    },
    {
      "epoch": 0.10669701604011808,
      "grad_norm": 0.959204375743866,
      "learning_rate": 3.556187766714083e-05,
      "loss": 3.6846,
      "step": 750
    },
    {
      "epoch": 0.1280364192481417,
      "grad_norm": 0.6349795460700989,
      "learning_rate": 4.267425320056899e-05,
      "loss": 3.6223,
      "step": 900
    },
    {
      "epoch": 0.14937582245616532,
      "grad_norm": 0.5802822113037109,
      "learning_rate": 4.978662873399716e-05,
      "loss": 3.61,
      "step": 1050
    },
    {
      "epoch": 0.17071522566418892,
      "grad_norm": 0.5859082937240601,
      "learning_rate": 5.6899004267425326e-05,
      "loss": 3.5972,
      "step": 1200
    },
    {
      "epoch": 0.19205462887221253,
      "grad_norm": 0.6196988821029663,
      "learning_rate": 6.40113798008535e-05,
      "loss": 3.5877,
      "step": 1350
    },
    {
      "epoch": 0.21339403208023616,
      "grad_norm": 0.5459500551223755,
      "learning_rate": 7.112375533428166e-05,
      "loss": 3.5782,
      "step": 1500
    },
    {
      "epoch": 0.23473343528825977,
      "grad_norm": 0.6327073574066162,
      "learning_rate": 7.823613086770982e-05,
      "loss": 3.6606,
      "step": 1650
    },
    {
      "epoch": 0.2560728384962834,
      "grad_norm": 0.6361453533172607,
      "learning_rate": 8.534850640113798e-05,
      "loss": 3.65,
      "step": 1800
    },
    {
      "epoch": 0.277412241704307,
      "grad_norm": 0.6123371720314026,
      "learning_rate": 9.246088193456614e-05,
      "loss": 3.5728,
      "step": 1950
    },
    {
      "epoch": 0.29875164491233064,
      "grad_norm": 0.666628360748291,
      "learning_rate": 9.957325746799432e-05,
      "loss": 3.6264,
      "step": 2100
    },
    {
      "epoch": 0.3200910481203542,
      "grad_norm": 0.5726816058158875,
      "learning_rate": 9.987747008161375e-05,
      "loss": 3.556,
      "step": 2250
    },
    {
      "epoch": 0.34143045132837785,
      "grad_norm": 0.6079813838005066,
      "learning_rate": 9.94787916264239e-05,
      "loss": 3.578,
      "step": 2400
    },
    {
      "epoch": 0.3627698545364015,
      "grad_norm": 0.6255538463592529,
      "learning_rate": 9.88056765053081e-05,
      "loss": 3.5943,
      "step": 2550
    },
    {
      "epoch": 0.38410925774442506,
      "grad_norm": 0.6345847249031067,
      "learning_rate": 9.786185818595117e-05,
      "loss": 3.6122,
      "step": 2700
    },
    {
      "epoch": 0.4054486609524487,
      "grad_norm": 0.6879974007606506,
      "learning_rate": 9.665257160526831e-05,
      "loss": 3.565,
      "step": 2850
    },
    {
      "epoch": 0.4267880641604723,
      "grad_norm": 0.6315012574195862,
      "learning_rate": 9.518452413355783e-05,
      "loss": 3.5804,
      "step": 3000
    },
    {
      "epoch": 0.4481274673684959,
      "grad_norm": 0.7176742553710938,
      "learning_rate": 9.34658583717264e-05,
      "loss": 3.5942,
      "step": 3150
    },
    {
      "epoch": 0.46946687057651953,
      "grad_norm": 0.6060994863510132,
      "learning_rate": 9.150610698793372e-05,
      "loss": 3.5308,
      "step": 3300
    },
    {
      "epoch": 0.49080627378454317,
      "grad_norm": 0.617668628692627,
      "learning_rate": 8.931613984415768e-05,
      "loss": 3.5876,
      "step": 3450
    },
    {
      "epoch": 0.5121456769925667,
      "grad_norm": 0.6864652037620544,
      "learning_rate": 8.690810370594507e-05,
      "loss": 3.5846,
      "step": 3600
    },
    {
      "epoch": 0.5334850802005904,
      "grad_norm": 0.6050401926040649,
      "learning_rate": 8.429535486975095e-05,
      "loss": 3.6127,
      "step": 3750
    },
    {
      "epoch": 0.554824483408614,
      "grad_norm": 0.693953275680542,
      "learning_rate": 8.14923850815525e-05,
      "loss": 3.5627,
      "step": 3900
    },
    {
      "epoch": 0.5761638866166376,
      "grad_norm": 0.6528810262680054,
      "learning_rate": 7.851474115763358e-05,
      "loss": 3.5785,
      "step": 4050
    },
    {
      "epoch": 0.5975032898246613,
      "grad_norm": 0.616762638092041,
      "learning_rate": 7.537893875336764e-05,
      "loss": 3.5832,
      "step": 4200
    },
    {
      "epoch": 0.6188426930326848,
      "grad_norm": 0.6996157169342041,
      "learning_rate": 7.210237075828447e-05,
      "loss": 3.587,
      "step": 4350
    },
    {
      "epoch": 0.6401820962407084,
      "grad_norm": 0.6142174601554871,
      "learning_rate": 6.870321082551293e-05,
      "loss": 3.5736,
      "step": 4500
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 0.6961992979049683,
      "learning_rate": 6.520031257067771e-05,
      "loss": 3.551,
      "step": 4650
    },
    {
      "epoch": 0.6828609026567557,
      "grad_norm": 0.768993079662323,
      "learning_rate": 6.161310499934934e-05,
      "loss": 3.5432,
      "step": 4800
    },
    {
      "epoch": 0.7042003058647793,
      "grad_norm": 0.6646748781204224,
      "learning_rate": 5.796148474306431e-05,
      "loss": 3.5214,
      "step": 4950
    },
    {
      "epoch": 0.725539709072803,
      "grad_norm": 0.6833208203315735,
      "learning_rate": 5.426570570163344e-05,
      "loss": 3.5519,
      "step": 5100
    },
    {
      "epoch": 0.7468791122808266,
      "grad_norm": 0.6871248483657837,
      "learning_rate": 5.0546266703843547e-05,
      "loss": 3.5536,
      "step": 5250
    },
    {
      "epoch": 0.7682185154888501,
      "grad_norm": 0.6826106309890747,
      "learning_rate": 4.6823797809647924e-05,
      "loss": 3.5717,
      "step": 5400
    },
    {
      "epoch": 0.7895579186968738,
      "grad_norm": 0.6835483908653259,
      "learning_rate": 4.3118945884476284e-05,
      "loss": 3.5493,
      "step": 5550
    },
    {
      "epoch": 0.8108973219048974,
      "grad_norm": 0.6668792963027954,
      "learning_rate": 3.945226008033238e-05,
      "loss": 3.5658,
      "step": 5700
    },
    {
      "epoch": 0.832236725112921,
      "grad_norm": 0.6708502173423767,
      "learning_rate": 3.584407785886416e-05,
      "loss": 3.5082,
      "step": 5850
    },
    {
      "epoch": 0.8535761283209446,
      "grad_norm": 0.654612123966217,
      "learning_rate": 3.231441218858521e-05,
      "loss": 3.5555,
      "step": 6000
    },
    {
      "epoch": 0.8749155315289683,
      "grad_norm": 0.6722510457038879,
      "learning_rate": 2.8882840541914434e-05,
      "loss": 3.5527,
      "step": 6150
    },
    {
      "epoch": 0.8962549347369918,
      "grad_norm": 0.7636847496032715,
      "learning_rate": 2.556839630771689e-05,
      "loss": 3.5663,
      "step": 6300
    },
    {
      "epoch": 0.9175943379450154,
      "grad_norm": 0.6945133209228516,
      "learning_rate": 2.2389463221632227e-05,
      "loss": 3.5603,
      "step": 6450
    },
    {
      "epoch": 0.9389337411530391,
      "grad_norm": 0.606469452381134,
      "learning_rate": 1.9363673399738234e-05,
      "loss": 3.5622,
      "step": 6600
    },
    {
      "epoch": 0.9602731443610627,
      "grad_norm": 0.7819713354110718,
      "learning_rate": 1.6507809541111046e-05,
      "loss": 3.5363,
      "step": 6750
    },
    {
      "epoch": 0.9816125475690863,
      "grad_norm": 0.7829970717430115,
      "learning_rate": 1.3837711841720158e-05,
      "loss": 3.5601,
      "step": 6900
    },
    {
      "epoch": 0.9999644343279867,
      "eval_loss": 0.8865013718605042,
      "eval_runtime": 1080.7601,
      "eval_samples_per_second": 23.125,
      "eval_steps_per_second": 2.891,
      "step": 7029
    },
    {
      "epoch": 1.0029519507771099,
      "grad_norm": 0.7631853222846985,
      "learning_rate": 1.1368190135965968e-05,
      "loss": 3.5771,
      "step": 7050
    },
    {
      "epoch": 1.0242913539851335,
      "grad_norm": 0.659477174282074,
      "learning_rate": 9.112941753170429e-06,
      "loss": 3.5113,
      "step": 7200
    },
    {
      "epoch": 1.0456307571931571,
      "grad_norm": 0.7869628667831421,
      "learning_rate": 7.084475544634539e-06,
      "loss": 3.5465,
      "step": 7350
    },
    {
      "epoch": 1.0669701604011808,
      "grad_norm": 0.7018013596534729,
      "learning_rate": 5.294042502650487e-06,
      "loss": 3.556,
      "step": 7500
    },
    {
      "epoch": 1.0883095636092044,
      "grad_norm": 0.7321258187294006,
      "learning_rate": 3.751573356293364e-06,
      "loss": 3.552,
      "step": 7650
    },
    {
      "epoch": 1.109648966817228,
      "grad_norm": 0.7771309614181519,
      "learning_rate": 2.4656234901209775e-06,
      "loss": 3.5257,
      "step": 7800
    },
    {
      "epoch": 1.1309883700252517,
      "grad_norm": 0.7827262878417969,
      "learning_rate": 1.4433254912927963e-06,
      "loss": 3.5367,
      "step": 7950
    },
    {
      "epoch": 1.1523277732332753,
      "grad_norm": 0.7429405450820923,
      "learning_rate": 6.903495883079314e-07,
      "loss": 3.5663,
      "step": 8100
    },
    {
      "epoch": 1.173667176441299,
      "grad_norm": 0.6554959416389465,
      "learning_rate": 2.1087220079071822e-07,
      "loss": 3.5605,
      "step": 8250
    },
    {
      "epoch": 1.1950065796493226,
      "grad_norm": 0.7164496183395386,
      "learning_rate": 7.552774764230109e-09,
      "loss": 3.5689,
      "step": 8400
    },
    {
      "epoch": 1.2163459828573462,
      "grad_norm": 0.7324621677398682,
      "learning_rate": 9.991848096810408e-05,
      "loss": 3.5379,
      "step": 8550
    },
    {
      "epoch": 1.2376853860653698,
      "grad_norm": 0.6984033584594727,
      "learning_rate": 9.956763928546866e-05,
      "loss": 3.5801,
      "step": 8700
    },
    {
      "epoch": 1.2590247892733935,
      "grad_norm": 0.7087857127189636,
      "learning_rate": 9.89418681387907e-05,
      "loss": 3.5371,
      "step": 8850
    },
    {
      "epoch": 1.2803641924814169,
      "grad_norm": 0.7679417729377747,
      "learning_rate": 9.804463839996259e-05,
      "loss": 3.5618,
      "step": 9000
    },
    {
      "epoch": 1.3017035956894405,
      "grad_norm": 0.6668902039527893,
      "learning_rate": 9.688092659993833e-05,
      "loss": 3.5444,
      "step": 9150
    },
    {
      "epoch": 1.3230429988974641,
      "grad_norm": 0.7132808566093445,
      "learning_rate": 9.545718732614818e-05,
      "loss": 3.5677,
      "step": 9300
    },
    {
      "epoch": 1.3443824021054878,
      "grad_norm": 0.7251027226448059,
      "learning_rate": 9.378131742179711e-05,
      "loss": 3.557,
      "step": 9450
    },
    {
      "epoch": 1.3657218053135114,
      "grad_norm": 0.712158203125,
      "learning_rate": 9.186261218561741e-05,
      "loss": 3.558,
      "step": 9600
    },
    {
      "epoch": 1.387061208521535,
      "grad_norm": 0.6859322786331177,
      "learning_rate": 8.971171381501526e-05,
      "loss": 3.5085,
      "step": 9750
    },
    {
      "epoch": 1.4084006117295587,
      "grad_norm": 0.6731730699539185,
      "learning_rate": 8.734055237857501e-05,
      "loss": 3.5599,
      "step": 9900
    },
    {
      "epoch": 1.4297400149375823,
      "grad_norm": 0.7222475409507751,
      "learning_rate": 8.476227964531934e-05,
      "loss": 3.5344,
      "step": 10050
    },
    {
      "epoch": 1.451079418145606,
      "grad_norm": 0.7687767148017883,
      "learning_rate": 8.199119613774486e-05,
      "loss": 3.6107,
      "step": 10200
    },
    {
      "epoch": 1.4724188213536296,
      "grad_norm": 0.7718508243560791,
      "learning_rate": 7.904267181323787e-05,
      "loss": 3.5599,
      "step": 10350
    },
    {
      "epoch": 1.493758224561653,
      "grad_norm": 0.6817260384559631,
      "learning_rate": 7.593306081381399e-05,
      "loss": 3.5655,
      "step": 10500
    },
    {
      "epoch": 1.5150976277696766,
      "grad_norm": 0.7188016772270203,
      "learning_rate": 7.26796107570272e-05,
      "loss": 3.5659,
      "step": 10650
    },
    {
      "epoch": 1.5364370309777002,
      "grad_norm": 0.703016996383667,
      "learning_rate": 6.930036707117098e-05,
      "loss": 3.5567,
      "step": 10800
    },
    {
      "epoch": 1.5577764341857239,
      "grad_norm": 0.6536404490470886,
      "learning_rate": 6.581407290538089e-05,
      "loss": 3.5213,
      "step": 10950
    },
    {
      "epoch": 1.5791158373937475,
      "grad_norm": 0.6996634602546692,
      "learning_rate": 6.224006516979239e-05,
      "loss": 3.554,
      "step": 11100
    },
    {
      "epoch": 1.6004552406017711,
      "grad_norm": 0.6749817132949829,
      "learning_rate": 5.8598167282373206e-05,
      "loss": 3.511,
      "step": 11250
    },
    {
      "epoch": 1.6217946438097948,
      "grad_norm": 0.7271940112113953,
      "learning_rate": 5.490857921731466e-05,
      "loss": 3.5199,
      "step": 11400
    },
    {
      "epoch": 1.6431340470178184,
      "grad_norm": 0.6851707100868225,
      "learning_rate": 5.1191765464834244e-05,
      "loss": 3.5252,
      "step": 11550
    },
    {
      "epoch": 1.664473450225842,
      "grad_norm": 0.7247000932693481,
      "learning_rate": 4.7468341523826845e-05,
      "loss": 3.5049,
      "step": 11700
    },
    {
      "epoch": 1.6858128534338657,
      "grad_norm": 0.6973866820335388,
      "learning_rate": 4.375895955693864e-05,
      "loss": 3.5085,
      "step": 11850
    },
    {
      "epoch": 1.7071522566418893,
      "grad_norm": 0.7645351886749268,
      "learning_rate": 4.008419384228294e-05,
      "loss": 3.5124,
      "step": 12000
    },
    {
      "epoch": 1.728491659849913,
      "grad_norm": 0.7234277725219727,
      "learning_rate": 3.646442665714752e-05,
      "loss": 3.4942,
      "step": 12150
    },
    {
      "epoch": 1.7498310630579366,
      "grad_norm": 0.7588704228401184,
      "learning_rate": 3.291973522664363e-05,
      "loss": 3.4991,
      "step": 12300
    },
    {
      "epoch": 1.7711704662659602,
      "grad_norm": 0.8762767314910889,
      "learning_rate": 2.9469780364343015e-05,
      "loss": 3.551,
      "step": 12450
    },
    {
      "epoch": 1.7925098694739838,
      "grad_norm": 0.7553567290306091,
      "learning_rate": 2.6133697422562964e-05,
      "loss": 3.4979,
      "step": 12600
    },
    {
      "epoch": 1.8138492726820075,
      "grad_norm": 0.7755456566810608,
      "learning_rate": 2.2929990157149167e-05,
      "loss": 3.4983,
      "step": 12750
    },
    {
      "epoch": 1.835188675890031,
      "grad_norm": 0.691287636756897,
      "learning_rate": 1.9876428095440936e-05,
      "loss": 3.5354,
      "step": 12900
    },
    {
      "epoch": 1.8565280790980545,
      "grad_norm": 0.7603293061256409,
      "learning_rate": 1.6989947976672776e-05,
      "loss": 3.5427,
      "step": 13050
    },
    {
      "epoch": 1.8778674823060781,
      "grad_norm": 0.7809168696403503,
      "learning_rate": 1.4286559811477834e-05,
      "loss": 3.5399,
      "step": 13200
    },
    {
      "epoch": 1.8992068855141018,
      "grad_norm": 0.7938318848609924,
      "learning_rate": 1.178125808153956e-05,
      "loss": 3.5136,
      "step": 13350
    },
    {
      "epoch": 1.9205462887221254,
      "grad_norm": 0.7441216111183167,
      "learning_rate": 9.487938571926675e-06,
      "loss": 3.5491,
      "step": 13500
    },
    {
      "epoch": 1.941885691930149,
      "grad_norm": 0.7662803530693054,
      "learning_rate": 7.4193212974058346e-06,
      "loss": 3.4982,
      "step": 13650
    },
    {
      "epoch": 1.9632250951381727,
      "grad_norm": 0.7392956018447876,
      "learning_rate": 5.5868799502244105e-06,
      "loss": 3.5136,
      "step": 13800
    },
    {
      "epoch": 1.9845644983461963,
      "grad_norm": 0.7719477415084839,
      "learning_rate": 4.0007782606857335e-06,
      "loss": 3.5028,
      "step": 13950
    },
    {
      "epoch": 1.9999288686559733,
      "eval_loss": 0.8820759654045105,
      "eval_runtime": 1081.2714,
      "eval_samples_per_second": 23.114,
      "eval_steps_per_second": 2.89,
      "step": 14058
    },
    {
      "epoch": 2.0059039015542197,
      "grad_norm": 0.6972760558128357,
      "learning_rate": 2.669813623495504e-06,
      "loss": 3.5314,
      "step": 14100
    },
    {
      "epoch": 2.0272433047622433,
      "grad_norm": 0.7139027714729309,
      "learning_rate": 1.6013683025588588e-06,
      "loss": 3.5417,
      "step": 14250
    },
    {
      "epoch": 2.048582707970267,
      "grad_norm": 0.7169308066368103,
      "learning_rate": 8.013684848735825e-07,
      "loss": 3.5186,
      "step": 14400
    },
    {
      "epoch": 2.0699221111782906,
      "grad_norm": 0.820012629032135,
      "learning_rate": 2.7425141062867864e-07,
      "loss": 3.5463,
      "step": 14550
    },
    {
      "epoch": 2.0912615143863142,
      "grad_norm": 0.7580754160881042,
      "learning_rate": 2.2940761823075917e-08,
      "loss": 3.5097,
      "step": 14700
    },
    {
      "epoch": 2.112600917594338,
      "grad_norm": 0.6735555529594421,
      "learning_rate": 9.995116955408706e-05,
      "loss": 3.5477,
      "step": 14850
    },
    {
      "epoch": 2.1339403208023615,
      "grad_norm": 0.7813335061073303,
      "learning_rate": 9.964822313556784e-05,
      "loss": 3.5443,
      "step": 15000
    },
    {
      "epoch": 2.155279724010385,
      "grad_norm": 0.7506726980209351,
      "learning_rate": 9.906990029053138e-05,
      "loss": 3.5413,
      "step": 15150
    },
    {
      "epoch": 2.1766191272184088,
      "grad_norm": 0.7476024627685547,
      "learning_rate": 9.82194087164215e-05,
      "loss": 3.519,
      "step": 15300
    },
    {
      "epoch": 2.1979585304264324,
      "grad_norm": 0.7848658561706543,
      "learning_rate": 9.71014657085545e-05,
      "loss": 3.518,
      "step": 15450
    },
    {
      "epoch": 2.219297933634456,
      "grad_norm": 0.722396969795227,
      "learning_rate": 9.572227199539783e-05,
      "loss": 3.5107,
      "step": 15600
    },
    {
      "epoch": 2.2406373368424797,
      "grad_norm": 0.6675618886947632,
      "learning_rate": 9.408947734591036e-05,
      "loss": 3.5354,
      "step": 15750
    },
    {
      "epoch": 2.2619767400505033,
      "grad_norm": 0.7218437790870667,
      "learning_rate": 9.221213813970481e-05,
      "loss": 3.556,
      "step": 15900
    },
    {
      "epoch": 2.283316143258527,
      "grad_norm": 0.7130675315856934,
      "learning_rate": 9.01006671353718e-05,
      "loss": 3.4974,
      "step": 16050
    },
    {
      "epoch": 2.3046555464665506,
      "grad_norm": 0.6568593978881836,
      "learning_rate": 8.776677571557824e-05,
      "loss": 3.4829,
      "step": 16200
    },
    {
      "epoch": 2.325994949674574,
      "grad_norm": 0.6343734860420227,
      "learning_rate": 8.52234089292798e-05,
      "loss": 3.4927,
      "step": 16350
    },
    {
      "epoch": 2.347334352882598,
      "grad_norm": 0.6878429055213928,
      "learning_rate": 8.248467369134089e-05,
      "loss": 3.519,
      "step": 16500
    },
    {
      "epoch": 2.3686737560906215,
      "grad_norm": 0.7476625442504883,
      "learning_rate": 7.956576053780422e-05,
      "loss": 3.5086,
      "step": 16650
    },
    {
      "epoch": 2.390013159298645,
      "grad_norm": 0.6957342028617859,
      "learning_rate": 7.648285937080061e-05,
      "loss": 3.516,
      "step": 16800
    },
    {
      "epoch": 2.4113525625066687,
      "grad_norm": 0.7482751607894897,
      "learning_rate": 7.325306966042307e-05,
      "loss": 3.5483,
      "step": 16950
    },
    {
      "epoch": 2.4326919657146924,
      "grad_norm": 0.7548587918281555,
      "learning_rate": 6.989430560163514e-05,
      "loss": 3.5395,
      "step": 17100
    },
    {
      "epoch": 2.454031368922716,
      "grad_norm": 0.620884358882904,
      "learning_rate": 6.642519675226607e-05,
      "loss": 3.5219,
      "step": 17250
    },
    {
      "epoch": 2.4753707721307396,
      "grad_norm": 1.5445235967636108,
      "learning_rate": 6.286498470320884e-05,
      "loss": 3.5342,
      "step": 17400
    },
    {
      "epoch": 2.4967101753387633,
      "grad_norm": 0.7476988434791565,
      "learning_rate": 5.923341635394538e-05,
      "loss": 3.508,
      "step": 17550
    },
    {
      "epoch": 2.518049578546787,
      "grad_norm": 0.8277643918991089,
      "learning_rate": 5.555063438535153e-05,
      "loss": 3.5278,
      "step": 17700
    },
    {
      "epoch": 2.53938898175481,
      "grad_norm": 0.6536219120025635,
      "learning_rate": 5.183706553728029e-05,
      "loss": 3.5418,
      "step": 17850
    },
    {
      "epoch": 2.5607283849628337,
      "grad_norm": 0.7497111558914185,
      "learning_rate": 4.811330731059718e-05,
      "loss": 3.5094,
      "step": 18000
    },
    {
      "epoch": 2.5820677881708574,
      "grad_norm": 0.7044046521186829,
      "learning_rate": 4.440001372208099e-05,
      "loss": 3.5456,
      "step": 18150
    },
    {
      "epoch": 2.603407191378881,
      "grad_norm": 0.6684650778770447,
      "learning_rate": 4.0717780745855895e-05,
      "loss": 3.5135,
      "step": 18300
    },
    {
      "epoch": 2.6247465945869046,
      "grad_norm": 0.6740185618400574,
      "learning_rate": 3.708703207676063e-05,
      "loss": 3.5162,
      "step": 18450
    },
    {
      "epoch": 2.6460859977949283,
      "grad_norm": 0.6485306620597839,
      "learning_rate": 3.352790584927259e-05,
      "loss": 3.538,
      "step": 18600
    },
    {
      "epoch": 2.667425401002952,
      "grad_norm": 0.6595690250396729,
      "learning_rate": 3.0060142940308495e-05,
      "loss": 3.5128,
      "step": 18750
    },
    {
      "epoch": 2.6887648042109755,
      "grad_norm": 0.7843319773674011,
      "learning_rate": 2.6702977475433544e-05,
      "loss": 3.5105,
      "step": 18900
    },
    {
      "epoch": 2.710104207418999,
      "grad_norm": 0.748256266117096,
      "learning_rate": 2.3475030145793547e-05,
      "loss": 3.4986,
      "step": 19050
    },
    {
      "epoch": 2.731443610627023,
      "grad_norm": 0.7368353605270386,
      "learning_rate": 2.039420492749235e-05,
      "loss": 3.528,
      "step": 19200
    },
    {
      "epoch": 2.7527830138350464,
      "grad_norm": 0.7020567655563354,
      "learning_rate": 1.7477589776266712e-05,
      "loss": 3.5364,
      "step": 19350
    },
    {
      "epoch": 2.77412241704307,
      "grad_norm": 0.7218824625015259,
      "learning_rate": 1.4741361848259077e-05,
      "loss": 3.5318,
      "step": 19500
    },
    {
      "epoch": 2.7954618202510937,
      "grad_norm": 0.8040801882743835,
      "learning_rate": 1.2200697772588782e-05,
      "loss": 3.493,
      "step": 19650
    },
    {
      "epoch": 2.8168012234591173,
      "grad_norm": 0.7881121039390564,
      "learning_rate": 9.869689473396199e-06,
      "loss": 3.5655,
      "step": 19800
    },
    {
      "epoch": 2.838140626667141,
      "grad_norm": 0.7243101000785828,
      "learning_rate": 7.761266008260304e-06,
      "loss": 3.5336,
      "step": 19950
    },
    {
      "epoch": 2.8594800298751646,
      "grad_norm": 0.6397539973258972,
      "learning_rate": 5.88712185651491e-06,
      "loss": 3.4959,
      "step": 20100
    },
    {
      "epoch": 2.880819433083188,
      "grad_norm": 0.7188803553581238,
      "learning_rate": 4.257652055216515e-06,
      "loss": 3.5305,
      "step": 20250
    },
    {
      "epoch": 2.902158836291212,
      "grad_norm": 0.7830621004104614,
      "learning_rate": 2.881894542536068e-06,
      "loss": 3.5131,
      "step": 20400
    },
    {
      "epoch": 2.9234982394992355,
      "grad_norm": 0.708651602268219,
      "learning_rate": 1.767480028369578e-06,
      "loss": 3.4685,
      "step": 20550
    },
    {
      "epoch": 2.944837642707259,
      "grad_norm": 0.7869004011154175,
      "learning_rate": 9.205896702124462e-07,
      "loss": 3.4918,
      "step": 20700
    },
    {
      "epoch": 2.9661770459152823,
      "grad_norm": 0.6764135956764221,
      "learning_rate": 3.4592078905125727e-07,
      "loss": 3.5269,
      "step": 20850
    },
    {
      "epoch": 2.987516449123306,
      "grad_norm": 0.7010588049888611,
      "learning_rate": 4.6660815430982216e-08,
      "loss": 3.4908,
      "step": 21000
    },
    {
      "epoch": 2.99989330298396,
      "eval_loss": 0.8794800043106079,
      "eval_runtime": 1081.5536,
      "eval_samples_per_second": 23.108,
      "eval_steps_per_second": 2.889,
      "step": 21087
    }
  ],
  "logging_steps": 150,
  "max_steps": 21087,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.3937325875382866e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
