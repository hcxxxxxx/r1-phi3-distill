{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.99989330298396,
  "eval_steps": 500,
  "global_step": 21087,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021339403208023616,
      "grad_norm": 1.5543808937072754,
      "learning_rate": 7.112375533428166e-06,
      "loss": 8.1906,
      "step": 150
    },
    {
      "epoch": 0.04267880641604723,
      "grad_norm": 3.5961010456085205,
      "learning_rate": 1.4224751066856332e-05,
      "loss": 6.7247,
      "step": 300
    },
    {
      "epoch": 0.06401820962407084,
      "grad_norm": 0.6384762525558472,
      "learning_rate": 2.1337126600284495e-05,
      "loss": 3.9669,
      "step": 450
    },
    {
      "epoch": 0.08535761283209446,
      "grad_norm": 0.6108381748199463,
      "learning_rate": 2.8449502133712663e-05,
      "loss": 3.7009,
      "step": 600
    },
    {
      "epoch": 0.10669701604011808,
      "grad_norm": 0.9705083966255188,
      "learning_rate": 3.556187766714083e-05,
      "loss": 3.6858,
      "step": 750
    },
    {
      "epoch": 0.1280364192481417,
      "grad_norm": 0.6429246068000793,
      "learning_rate": 4.267425320056899e-05,
      "loss": 3.6231,
      "step": 900
    },
    {
      "epoch": 0.14937582245616532,
      "grad_norm": 0.5937695503234863,
      "learning_rate": 4.978662873399716e-05,
      "loss": 3.6109,
      "step": 1050
    },
    {
      "epoch": 0.17071522566418892,
      "grad_norm": 0.6140595078468323,
      "learning_rate": 5.6899004267425326e-05,
      "loss": 3.5981,
      "step": 1200
    },
    {
      "epoch": 0.19205462887221253,
      "grad_norm": 0.6155059933662415,
      "learning_rate": 6.40113798008535e-05,
      "loss": 3.5886,
      "step": 1350
    },
    {
      "epoch": 0.21339403208023616,
      "grad_norm": 0.5528745651245117,
      "learning_rate": 7.112375533428166e-05,
      "loss": 3.5785,
      "step": 1500
    },
    {
      "epoch": 0.23473343528825977,
      "grad_norm": 0.6408244371414185,
      "learning_rate": 7.823613086770982e-05,
      "loss": 3.661,
      "step": 1650
    },
    {
      "epoch": 0.2560728384962834,
      "grad_norm": 0.6374792456626892,
      "learning_rate": 8.534850640113798e-05,
      "loss": 3.6498,
      "step": 1800
    },
    {
      "epoch": 0.277412241704307,
      "grad_norm": 0.6038277745246887,
      "learning_rate": 9.246088193456614e-05,
      "loss": 3.5729,
      "step": 1950
    },
    {
      "epoch": 0.29875164491233064,
      "grad_norm": 0.6521636247634888,
      "learning_rate": 9.957325746799432e-05,
      "loss": 3.626,
      "step": 2100
    },
    {
      "epoch": 0.3200910481203542,
      "grad_norm": 0.5661469101905823,
      "learning_rate": 9.998638061873831e-05,
      "loss": 3.5565,
      "step": 2250
    },
    {
      "epoch": 0.34143045132837785,
      "grad_norm": 0.5897999405860901,
      "learning_rate": 9.994199828119764e-05,
      "loss": 3.5779,
      "step": 2400
    },
    {
      "epoch": 0.3627698545364015,
      "grad_norm": 0.6151385307312012,
      "learning_rate": 9.986682485956562e-05,
      "loss": 3.5949,
      "step": 2550
    },
    {
      "epoch": 0.38410925774442506,
      "grad_norm": 0.6210452318191528,
      "learning_rate": 9.976090670102949e-05,
      "loss": 3.6122,
      "step": 2700
    },
    {
      "epoch": 0.4054486609524487,
      "grad_norm": 0.6850053668022156,
      "learning_rate": 9.962430910804087e-05,
      "loss": 3.5656,
      "step": 2850
    },
    {
      "epoch": 0.4267880641604723,
      "grad_norm": 0.6170728802680969,
      "learning_rate": 9.945711629805438e-05,
      "loss": 3.5808,
      "step": 3000
    },
    {
      "epoch": 0.4481274673684959,
      "grad_norm": 0.7047150731086731,
      "learning_rate": 9.925943135160438e-05,
      "loss": 3.5945,
      "step": 3150
    },
    {
      "epoch": 0.46946687057651953,
      "grad_norm": 0.5931646823883057,
      "learning_rate": 9.903137614875215e-05,
      "loss": 3.531,
      "step": 3300
    },
    {
      "epoch": 0.49080627378454317,
      "grad_norm": 0.6021033525466919,
      "learning_rate": 9.877309129394225e-05,
      "loss": 3.588,
      "step": 3450
    },
    {
      "epoch": 0.5121456769925667,
      "grad_norm": 0.6555029153823853,
      "learning_rate": 9.84847360293147e-05,
      "loss": 3.5851,
      "step": 3600
    },
    {
      "epoch": 0.5334850802005904,
      "grad_norm": 0.5918014049530029,
      "learning_rate": 9.816648813652638e-05,
      "loss": 3.613,
      "step": 3750
    },
    {
      "epoch": 0.554824483408614,
      "grad_norm": 0.6752801537513733,
      "learning_rate": 9.7818543827142e-05,
      "loss": 3.5628,
      "step": 3900
    },
    {
      "epoch": 0.5761638866166376,
      "grad_norm": 0.6303569674491882,
      "learning_rate": 9.744111762166251e-05,
      "loss": 3.5787,
      "step": 4050
    },
    {
      "epoch": 0.5975032898246613,
      "grad_norm": 0.5910407900810242,
      "learning_rate": 9.703444221726528e-05,
      "loss": 3.5829,
      "step": 4200
    },
    {
      "epoch": 0.6188426930326848,
      "grad_norm": 0.6735965013504028,
      "learning_rate": 9.659876834433766e-05,
      "loss": 3.5867,
      "step": 4350
    },
    {
      "epoch": 0.6401820962407084,
      "grad_norm": 0.5877043008804321,
      "learning_rate": 9.613436461189247e-05,
      "loss": 3.5736,
      "step": 4500
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 0.9638991355895996,
      "learning_rate": 9.56415173419607e-05,
      "loss": 3.5507,
      "step": 4650
    },
    {
      "epoch": 0.6828609026567557,
      "grad_norm": 0.764531672000885,
      "learning_rate": 9.512053039306333e-05,
      "loss": 3.5424,
      "step": 4800
    },
    {
      "epoch": 0.7042003058647793,
      "grad_norm": 0.6266080737113953,
      "learning_rate": 9.457172497287135e-05,
      "loss": 3.5211,
      "step": 4950
    },
    {
      "epoch": 0.725539709072803,
      "grad_norm": 0.631537914276123,
      "learning_rate": 9.399543944016948e-05,
      "loss": 3.5512,
      "step": 5100
    },
    {
      "epoch": 0.7468791122808266,
      "grad_norm": 0.637639045715332,
      "learning_rate": 9.339202909624538e-05,
      "loss": 3.5537,
      "step": 5250
    },
    {
      "epoch": 0.7682185154888501,
      "grad_norm": 0.6313830614089966,
      "learning_rate": 9.276186596583334e-05,
      "loss": 3.571,
      "step": 5400
    },
    {
      "epoch": 0.7895579186968738,
      "grad_norm": 0.6238035559654236,
      "learning_rate": 9.210533856774735e-05,
      "loss": 3.5493,
      "step": 5550
    },
    {
      "epoch": 0.8108973219048974,
      "grad_norm": 0.6260513067245483,
      "learning_rate": 9.142285167534485e-05,
      "loss": 3.5654,
      "step": 5700
    },
    {
      "epoch": 0.832236725112921,
      "grad_norm": 0.6090871095657349,
      "learning_rate": 9.071482606696914e-05,
      "loss": 3.5068,
      "step": 5850
    },
    {
      "epoch": 0.8535761283209446,
      "grad_norm": 0.6004143357276917,
      "learning_rate": 8.998169826652383e-05,
      "loss": 3.5544,
      "step": 6000
    },
    {
      "epoch": 0.8749155315289683,
      "grad_norm": 0.6051623225212097,
      "learning_rate": 8.922392027433994e-05,
      "loss": 3.5513,
      "step": 6150
    },
    {
      "epoch": 0.8962549347369918,
      "grad_norm": 0.6989708542823792,
      "learning_rate": 8.844195928850088e-05,
      "loss": 3.5636,
      "step": 6300
    },
    {
      "epoch": 0.9175943379450154,
      "grad_norm": 0.6151857972145081,
      "learning_rate": 8.763629741679769e-05,
      "loss": 3.5581,
      "step": 6450
    },
    {
      "epoch": 0.9389337411530391,
      "grad_norm": 0.5526039600372314,
      "learning_rate": 8.680743137949176e-05,
      "loss": 3.5595,
      "step": 6600
    },
    {
      "epoch": 0.9602731443610627,
      "grad_norm": 0.725918173789978,
      "learning_rate": 8.59558722030685e-05,
      "loss": 3.5326,
      "step": 6750
    },
    {
      "epoch": 0.9816125475690863,
      "grad_norm": 0.6503398418426514,
      "learning_rate": 8.508214490517064e-05,
      "loss": 3.5562,
      "step": 6900
    },
    {
      "epoch": 0.9999644343279867,
      "eval_loss": 0.8854365944862366,
      "eval_runtime": 1085.3935,
      "eval_samples_per_second": 23.027,
      "eval_steps_per_second": 2.879,
      "step": 7029
    },
    {
      "epoch": 1.0029519507771099,
      "grad_norm": 0.6783682107925415,
      "learning_rate": 8.418678817090542e-05,
      "loss": 3.5726,
      "step": 7050
    },
    {
      "epoch": 1.0242913539851335,
      "grad_norm": 0.5978647470474243,
      "learning_rate": 8.32703540207255e-05,
      "loss": 3.5046,
      "step": 7200
    },
    {
      "epoch": 1.0456307571931571,
      "grad_norm": 0.6696200370788574,
      "learning_rate": 8.23334074700879e-05,
      "loss": 3.5411,
      "step": 7350
    },
    {
      "epoch": 1.0669701604011808,
      "grad_norm": 0.6200745105743408,
      "learning_rate": 8.137652618110109e-05,
      "loss": 3.5495,
      "step": 7500
    },
    {
      "epoch": 1.0883095636092044,
      "grad_norm": 0.663536787033081,
      "learning_rate": 8.040030010637508e-05,
      "loss": 3.545,
      "step": 7650
    },
    {
      "epoch": 1.109648966817228,
      "grad_norm": 0.7061002254486084,
      "learning_rate": 7.940533112529383e-05,
      "loss": 3.5185,
      "step": 7800
    },
    {
      "epoch": 1.1309883700252517,
      "grad_norm": 0.7705827951431274,
      "learning_rate": 7.83922326729344e-05,
      "loss": 3.5287,
      "step": 7950
    },
    {
      "epoch": 1.1523277732332753,
      "grad_norm": 0.6803449988365173,
      "learning_rate": 7.736162936186166e-05,
      "loss": 3.5575,
      "step": 8100
    },
    {
      "epoch": 1.173667176441299,
      "grad_norm": 0.6058776378631592,
      "learning_rate": 7.631415659703149e-05,
      "loss": 3.5518,
      "step": 8250
    },
    {
      "epoch": 1.1950065796493226,
      "grad_norm": 0.6646082997322083,
      "learning_rate": 7.52504601840403e-05,
      "loss": 3.5591,
      "step": 8400
    },
    {
      "epoch": 1.2163459828573462,
      "grad_norm": 0.6559336185455322,
      "learning_rate": 7.417119593096198e-05,
      "loss": 3.5251,
      "step": 8550
    },
    {
      "epoch": 1.2376853860653698,
      "grad_norm": 0.6534264087677002,
      "learning_rate": 7.307702924401813e-05,
      "loss": 3.5644,
      "step": 8700
    },
    {
      "epoch": 1.2590247892733935,
      "grad_norm": 0.6377343535423279,
      "learning_rate": 7.196863471733042e-05,
      "loss": 3.5212,
      "step": 8850
    },
    {
      "epoch": 1.2803641924814169,
      "grad_norm": 0.7130004167556763,
      "learning_rate": 7.084669571700864e-05,
      "loss": 3.5461,
      "step": 9000
    },
    {
      "epoch": 1.3017035956894405,
      "grad_norm": 0.6309349536895752,
      "learning_rate": 6.97119039598301e-05,
      "loss": 3.5291,
      "step": 9150
    },
    {
      "epoch": 1.3230429988974641,
      "grad_norm": 0.6882803440093994,
      "learning_rate": 6.856495908677078e-05,
      "loss": 3.5529,
      "step": 9300
    },
    {
      "epoch": 1.3443824021054878,
      "grad_norm": 0.6963500380516052,
      "learning_rate": 6.740656823165093e-05,
      "loss": 3.5422,
      "step": 9450
    },
    {
      "epoch": 1.3657218053135114,
      "grad_norm": 0.6701694130897522,
      "learning_rate": 6.623744558516091e-05,
      "loss": 3.5429,
      "step": 9600
    },
    {
      "epoch": 1.387061208521535,
      "grad_norm": 0.661002516746521,
      "learning_rate": 6.505831195453635e-05,
      "loss": 3.494,
      "step": 9750
    },
    {
      "epoch": 1.4084006117295587,
      "grad_norm": 0.6417263746261597,
      "learning_rate": 6.38698943191538e-05,
      "loss": 3.5459,
      "step": 9900
    },
    {
      "epoch": 1.4297400149375823,
      "grad_norm": 0.6964667439460754,
      "learning_rate": 6.26729253823212e-05,
      "loss": 3.5214,
      "step": 10050
    },
    {
      "epoch": 1.451079418145606,
      "grad_norm": 0.7448593378067017,
      "learning_rate": 6.14681431195393e-05,
      "loss": 3.5978,
      "step": 10200
    },
    {
      "epoch": 1.4724188213536296,
      "grad_norm": 0.6349177956581116,
      "learning_rate": 6.025629032351248e-05,
      "loss": 3.5465,
      "step": 10350
    },
    {
      "epoch": 1.493758224561653,
      "grad_norm": 0.6689891219139099,
      "learning_rate": 5.903811414618964e-05,
      "loss": 3.5534,
      "step": 10500
    },
    {
      "epoch": 1.5150976277696766,
      "grad_norm": 0.7000115513801575,
      "learning_rate": 5.781436563811752e-05,
      "loss": 3.5545,
      "step": 10650
    },
    {
      "epoch": 1.5364370309777002,
      "grad_norm": 0.6878937482833862,
      "learning_rate": 5.6585799285390296e-05,
      "loss": 3.545,
      "step": 10800
    },
    {
      "epoch": 1.5577764341857239,
      "grad_norm": 0.6398700475692749,
      "learning_rate": 5.5353172544481114e-05,
      "loss": 3.51,
      "step": 10950
    },
    {
      "epoch": 1.5791158373937475,
      "grad_norm": 0.6863448023796082,
      "learning_rate": 5.411724537524214e-05,
      "loss": 3.5436,
      "step": 11100
    },
    {
      "epoch": 1.6004552406017711,
      "grad_norm": 0.6421598792076111,
      "learning_rate": 5.287877977236142e-05,
      "loss": 3.5,
      "step": 11250
    },
    {
      "epoch": 1.6217946438097948,
      "grad_norm": 0.7033826112747192,
      "learning_rate": 5.16385392955649e-05,
      "loss": 3.5101,
      "step": 11400
    },
    {
      "epoch": 1.6431340470178184,
      "grad_norm": 0.664759635925293,
      "learning_rate": 5.0397288598853845e-05,
      "loss": 3.5148,
      "step": 11550
    },
    {
      "epoch": 1.664473450225842,
      "grad_norm": 0.712027907371521,
      "learning_rate": 4.915579295906726e-05,
      "loss": 3.4943,
      "step": 11700
    },
    {
      "epoch": 1.6858128534338657,
      "grad_norm": 0.6714968681335449,
      "learning_rate": 4.791481780406068e-05,
      "loss": 3.4983,
      "step": 11850
    },
    {
      "epoch": 1.7071522566418893,
      "grad_norm": 0.7361525893211365,
      "learning_rate": 4.6675128240791524e-05,
      "loss": 3.5033,
      "step": 12000
    },
    {
      "epoch": 1.728491659849913,
      "grad_norm": 0.6979562640190125,
      "learning_rate": 4.5437488583602516e-05,
      "loss": 3.4851,
      "step": 12150
    },
    {
      "epoch": 1.7498310630579366,
      "grad_norm": 0.7346245646476746,
      "learning_rate": 4.420266188299362e-05,
      "loss": 3.4898,
      "step": 12300
    },
    {
      "epoch": 1.7711704662659602,
      "grad_norm": 0.8039990067481995,
      "learning_rate": 4.2971409455173386e-05,
      "loss": 3.543,
      "step": 12450
    },
    {
      "epoch": 1.7925098694739838,
      "grad_norm": 0.7283027768135071,
      "learning_rate": 4.174449041267928e-05,
      "loss": 3.4889,
      "step": 12600
    },
    {
      "epoch": 1.8138492726820075,
      "grad_norm": 0.726063072681427,
      "learning_rate": 4.0522661196356885e-05,
      "loss": 3.4896,
      "step": 12750
    },
    {
      "epoch": 1.835188675890031,
      "grad_norm": 0.6634626388549805,
      "learning_rate": 3.930667510898627e-05,
      "loss": 3.5262,
      "step": 12900
    },
    {
      "epoch": 1.8565280790980545,
      "grad_norm": 0.7446542382240295,
      "learning_rate": 3.80972818508429e-05,
      "loss": 3.5338,
      "step": 13050
    },
    {
      "epoch": 1.8778674823060781,
      "grad_norm": 0.7466264963150024,
      "learning_rate": 3.6895227057479865e-05,
      "loss": 3.5321,
      "step": 13200
    },
    {
      "epoch": 1.8992068855141018,
      "grad_norm": 0.7646104097366333,
      "learning_rate": 3.570125184001605e-05,
      "loss": 3.5048,
      "step": 13350
    },
    {
      "epoch": 1.9205462887221254,
      "grad_norm": 0.7224619388580322,
      "learning_rate": 3.451609232821376e-05,
      "loss": 3.5415,
      "step": 13500
    },
    {
      "epoch": 1.941885691930149,
      "grad_norm": 0.7231233716011047,
      "learning_rate": 3.3340479216627585e-05,
      "loss": 3.4887,
      "step": 13650
    },
    {
      "epoch": 1.9632250951381727,
      "grad_norm": 0.7229027152061462,
      "learning_rate": 3.217513731410426e-05,
      "loss": 3.5063,
      "step": 13800
    },
    {
      "epoch": 1.9845644983461963,
      "grad_norm": 0.7508575916290283,
      "learning_rate": 3.1020785096911254e-05,
      "loss": 3.4941,
      "step": 13950
    },
    {
      "epoch": 1.9999288686559733,
      "eval_loss": 0.8801495432853699,
      "eval_runtime": 1083.3251,
      "eval_samples_per_second": 23.071,
      "eval_steps_per_second": 2.885,
      "step": 14058
    },
    {
      "epoch": 2.0059039015542197,
      "grad_norm": 0.6723387837409973,
      "learning_rate": 2.987813426576972e-05,
      "loss": 3.5218,
      "step": 14100
    },
    {
      "epoch": 2.0272433047622433,
      "grad_norm": 0.693481981754303,
      "learning_rate": 2.8747889307064625e-05,
      "loss": 3.5307,
      "step": 14250
    },
    {
      "epoch": 2.048582707970267,
      "grad_norm": 0.7231296300888062,
      "learning_rate": 2.7630747058503015e-05,
      "loss": 3.5082,
      "step": 14400
    },
    {
      "epoch": 2.0699221111782906,
      "grad_norm": 0.8044787049293518,
      "learning_rate": 2.6527396279487827e-05,
      "loss": 3.5357,
      "step": 14550
    },
    {
      "epoch": 2.0912615143863142,
      "grad_norm": 0.7112867832183838,
      "learning_rate": 2.5438517226472314e-05,
      "loss": 3.4991,
      "step": 14700
    },
    {
      "epoch": 2.112600917594338,
      "grad_norm": 0.6325015425682068,
      "learning_rate": 2.436478123355684e-05,
      "loss": 3.5353,
      "step": 14850
    },
    {
      "epoch": 2.1339403208023615,
      "grad_norm": 0.7615137696266174,
      "learning_rate": 2.3306850298586675e-05,
      "loss": 3.5281,
      "step": 15000
    },
    {
      "epoch": 2.155279724010385,
      "grad_norm": 0.7176252603530884,
      "learning_rate": 2.226537667500581e-05,
      "loss": 3.5244,
      "step": 15150
    },
    {
      "epoch": 2.1766191272184088,
      "grad_norm": 0.748016893863678,
      "learning_rate": 2.124100246971887e-05,
      "loss": 3.5017,
      "step": 15300
    },
    {
      "epoch": 2.1979585304264324,
      "grad_norm": 0.8052937984466553,
      "learning_rate": 2.0234359247208207e-05,
      "loss": 3.5019,
      "step": 15450
    },
    {
      "epoch": 2.219297933634456,
      "grad_norm": 0.7399562001228333,
      "learning_rate": 1.9246067640151382e-05,
      "loss": 3.4944,
      "step": 15600
    },
    {
      "epoch": 2.2406373368424797,
      "grad_norm": 0.692893922328949,
      "learning_rate": 1.827673696677808e-05,
      "loss": 3.5189,
      "step": 15750
    },
    {
      "epoch": 2.2619767400505033,
      "grad_norm": 0.743442177772522,
      "learning_rate": 1.7326964855202977e-05,
      "loss": 3.541,
      "step": 15900
    },
    {
      "epoch": 2.283316143258527,
      "grad_norm": 0.7534196972846985,
      "learning_rate": 1.6397336874965968e-05,
      "loss": 3.4819,
      "step": 16050
    },
    {
      "epoch": 2.3046555464665506,
      "grad_norm": 0.6760962605476379,
      "learning_rate": 1.5488426176006975e-05,
      "loss": 3.4673,
      "step": 16200
    },
    {
      "epoch": 2.325994949674574,
      "grad_norm": 0.665072500705719,
      "learning_rate": 1.4600793135297774e-05,
      "loss": 3.4784,
      "step": 16350
    },
    {
      "epoch": 2.347334352882598,
      "grad_norm": 0.7044408321380615,
      "learning_rate": 1.3734985011349044e-05,
      "loss": 3.5043,
      "step": 16500
    },
    {
      "epoch": 2.3686737560906215,
      "grad_norm": 0.7922499775886536,
      "learning_rate": 1.289153560680525e-05,
      "loss": 3.4944,
      "step": 16650
    },
    {
      "epoch": 2.390013159298645,
      "grad_norm": 0.7203784584999084,
      "learning_rate": 1.2070964939335549e-05,
      "loss": 3.5023,
      "step": 16800
    },
    {
      "epoch": 2.4113525625066687,
      "grad_norm": 0.7854844927787781,
      "learning_rate": 1.1273778921023925e-05,
      "loss": 3.5349,
      "step": 16950
    },
    {
      "epoch": 2.4326919657146924,
      "grad_norm": 0.8045425415039062,
      "learning_rate": 1.0500469046455452e-05,
      "loss": 3.526,
      "step": 17100
    },
    {
      "epoch": 2.454031368922716,
      "grad_norm": 0.6476894021034241,
      "learning_rate": 9.751512089692016e-06,
      "loss": 3.5091,
      "step": 17250
    },
    {
      "epoch": 2.4753707721307396,
      "grad_norm": 1.5211118459701538,
      "learning_rate": 9.027369810323305e-06,
      "loss": 3.5223,
      "step": 17400
    },
    {
      "epoch": 2.4967101753387633,
      "grad_norm": 0.785840630531311,
      "learning_rate": 8.328488668775142e-06,
      "loss": 3.4964,
      "step": 17550
    },
    {
      "epoch": 2.518049578546787,
      "grad_norm": 0.873801589012146,
      "learning_rate": 7.655299551050088e-06,
      "loss": 3.5167,
      "step": 17700
    },
    {
      "epoch": 2.53938898175481,
      "grad_norm": 0.6762769818305969,
      "learning_rate": 7.008217503070347e-06,
      "loss": 3.5311,
      "step": 17850
    },
    {
      "epoch": 2.5607283849628337,
      "grad_norm": 0.7783177495002747,
      "learning_rate": 6.387641474786627e-06,
      "loss": 3.4982,
      "step": 18000
    },
    {
      "epoch": 2.5820677881708574,
      "grad_norm": 0.7277793884277344,
      "learning_rate": 5.793954074210828e-06,
      "loss": 3.535,
      "step": 18150
    },
    {
      "epoch": 2.603407191378881,
      "grad_norm": 0.6924830675125122,
      "learning_rate": 5.227521331524038e-06,
      "loss": 3.5039,
      "step": 18300
    },
    {
      "epoch": 2.6247465945869046,
      "grad_norm": 0.698665201663971,
      "learning_rate": 4.688692473405459e-06,
      "loss": 3.507,
      "step": 18450
    },
    {
      "epoch": 2.6460859977949283,
      "grad_norm": 0.6792811155319214,
      "learning_rate": 4.17779970772127e-06,
      "loss": 3.5291,
      "step": 18600
    },
    {
      "epoch": 2.667425401002952,
      "grad_norm": 0.6896216869354248,
      "learning_rate": 3.695158018706174e-06,
      "loss": 3.5033,
      "step": 18750
    },
    {
      "epoch": 2.6887648042109755,
      "grad_norm": 0.8153684139251709,
      "learning_rate": 3.2410649727641183e-06,
      "loss": 3.5026,
      "step": 18900
    },
    {
      "epoch": 2.710104207418999,
      "grad_norm": 0.7754663825035095,
      "learning_rate": 2.81580053500749e-06,
      "loss": 3.49,
      "step": 19050
    },
    {
      "epoch": 2.731443610627023,
      "grad_norm": 0.7432405948638916,
      "learning_rate": 2.4196268966483917e-06,
      "loss": 3.5208,
      "step": 19200
    },
    {
      "epoch": 2.7527830138350464,
      "grad_norm": 0.6753481030464172,
      "learning_rate": 2.052788313348064e-06,
      "loss": 3.528,
      "step": 19350
    },
    {
      "epoch": 2.77412241704307,
      "grad_norm": 0.7348329424858093,
      "learning_rate": 1.7155109546242498e-06,
      "loss": 3.5251,
      "step": 19500
    },
    {
      "epoch": 2.7954618202510937,
      "grad_norm": 0.8286206126213074,
      "learning_rate": 1.4080027644093441e-06,
      "loss": 3.4864,
      "step": 19650
    },
    {
      "epoch": 2.8168012234591173,
      "grad_norm": 0.8093932867050171,
      "learning_rate": 1.1304533328453104e-06,
      "loss": 3.5584,
      "step": 19800
    },
    {
      "epoch": 2.838140626667141,
      "grad_norm": 0.7325654029846191,
      "learning_rate": 8.830337793943378e-07,
      "loss": 3.5268,
      "step": 19950
    },
    {
      "epoch": 2.8594800298751646,
      "grad_norm": 0.6557959318161011,
      "learning_rate": 6.658966473373939e-07,
      "loss": 3.4893,
      "step": 20100
    },
    {
      "epoch": 2.880819433083188,
      "grad_norm": 0.7294430732727051,
      "learning_rate": 4.791758097256849e-07,
      "loss": 3.5239,
      "step": 20250
    },
    {
      "epoch": 2.902158836291212,
      "grad_norm": 0.7982224822044373,
      "learning_rate": 3.229863868429328e-07,
      "loss": 3.5068,
      "step": 20400
    },
    {
      "epoch": 2.9234982394992355,
      "grad_norm": 0.7278009653091431,
      "learning_rate": 1.974246752295239e-07,
      "loss": 3.4617,
      "step": 20550
    },
    {
      "epoch": 2.944837642707259,
      "grad_norm": 0.7383383512496948,
      "learning_rate": 1.0256808831212162e-07,
      "loss": 3.4849,
      "step": 20700
    },
    {
      "epoch": 2.9661770459152823,
      "grad_norm": 0.6947291493415833,
      "learning_rate": 3.847510867540649e-08,
      "loss": 3.5202,
      "step": 20850
    },
    {
      "epoch": 2.987516449123306,
      "grad_norm": 0.7244181632995605,
      "learning_rate": 5.185252005457386e-09,
      "loss": 3.4846,
      "step": 21000
    },
    {
      "epoch": 2.99989330298396,
      "eval_loss": 0.8791918158531189,
      "eval_runtime": 1083.8788,
      "eval_samples_per_second": 23.059,
      "eval_steps_per_second": 2.883,
      "step": 21087
    }
  ],
  "logging_steps": 150,
  "max_steps": 21087,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.3937325875382866e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
