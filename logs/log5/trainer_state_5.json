{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999644343279867,
  "eval_steps": 500,
  "global_step": 7029,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007113134402674539,
      "grad_norm": 2.0235579013824463,
      "learning_rate": 7.112375533428166e-06,
      "loss": 8.3683,
      "step": 50
    },
    {
      "epoch": 0.014226268805349078,
      "grad_norm": 1.2538872957229614,
      "learning_rate": 1.4224751066856332e-05,
      "loss": 7.9372,
      "step": 100
    },
    {
      "epoch": 0.021339403208023616,
      "grad_norm": 2.4434397220611572,
      "learning_rate": 2.1337126600284495e-05,
      "loss": 7.1162,
      "step": 150
    },
    {
      "epoch": 0.028452537610698155,
      "grad_norm": 0.9190266728401184,
      "learning_rate": 2.8449502133712663e-05,
      "loss": 5.2027,
      "step": 200
    },
    {
      "epoch": 0.03556567201337269,
      "grad_norm": 0.510299026966095,
      "learning_rate": 3.556187766714083e-05,
      "loss": 3.8977,
      "step": 250
    },
    {
      "epoch": 0.04267880641604723,
      "grad_norm": 0.5576338171958923,
      "learning_rate": 4.267425320056899e-05,
      "loss": 3.7882,
      "step": 300
    },
    {
      "epoch": 0.04979194081872177,
      "grad_norm": 0.4069212079048157,
      "learning_rate": 4.978662873399716e-05,
      "loss": 3.6588,
      "step": 350
    },
    {
      "epoch": 0.05690507522139631,
      "grad_norm": 0.5220137238502502,
      "learning_rate": 5.6899004267425326e-05,
      "loss": 3.6711,
      "step": 400
    },
    {
      "epoch": 0.06401820962407084,
      "grad_norm": 0.5249077677726746,
      "learning_rate": 6.40113798008535e-05,
      "loss": 3.6464,
      "step": 450
    },
    {
      "epoch": 0.07113134402674538,
      "grad_norm": 0.6531096696853638,
      "learning_rate": 7.112375533428166e-05,
      "loss": 3.6742,
      "step": 500
    },
    {
      "epoch": 0.07824447842941992,
      "grad_norm": 0.5417676568031311,
      "learning_rate": 7.823613086770982e-05,
      "loss": 3.6705,
      "step": 550
    },
    {
      "epoch": 0.08535761283209446,
      "grad_norm": 0.5592722296714783,
      "learning_rate": 8.534850640113798e-05,
      "loss": 3.5648,
      "step": 600
    },
    {
      "epoch": 0.092470747234769,
      "grad_norm": 0.5211864113807678,
      "learning_rate": 9.246088193456614e-05,
      "loss": 3.6781,
      "step": 650
    },
    {
      "epoch": 0.09958388163744354,
      "grad_norm": 0.7872294783592224,
      "learning_rate": 9.957325746799432e-05,
      "loss": 3.6697,
      "step": 700
    },
    {
      "epoch": 0.10669701604011808,
      "grad_norm": 0.6824262142181396,
      "learning_rate": 9.998638061873831e-05,
      "loss": 3.5756,
      "step": 750
    },
    {
      "epoch": 0.11381015044279262,
      "grad_norm": 0.6101523637771606,
      "learning_rate": 9.994199828119764e-05,
      "loss": 3.5748,
      "step": 800
    },
    {
      "epoch": 0.12092328484546716,
      "grad_norm": 0.5531458258628845,
      "learning_rate": 9.986682485956562e-05,
      "loss": 3.5897,
      "step": 850
    },
    {
      "epoch": 0.1280364192481417,
      "grad_norm": 0.5611907839775085,
      "learning_rate": 9.976090670102949e-05,
      "loss": 3.596,
      "step": 900
    },
    {
      "epoch": 0.13514955365081624,
      "grad_norm": 0.569665789604187,
      "learning_rate": 9.962430910804087e-05,
      "loss": 3.5985,
      "step": 950
    },
    {
      "epoch": 0.14226268805349077,
      "grad_norm": 0.6043210625648499,
      "learning_rate": 9.945711629805438e-05,
      "loss": 3.5718,
      "step": 1000
    },
    {
      "epoch": 0.14937582245616532,
      "grad_norm": 0.48091551661491394,
      "learning_rate": 9.925943135160438e-05,
      "loss": 3.5665,
      "step": 1050
    },
    {
      "epoch": 0.15648895685883984,
      "grad_norm": 0.5668348073959351,
      "learning_rate": 9.903137614875215e-05,
      "loss": 3.5598,
      "step": 1100
    },
    {
      "epoch": 0.1636020912615144,
      "grad_norm": 0.5942012667655945,
      "learning_rate": 9.877309129394225e-05,
      "loss": 3.6066,
      "step": 1150
    },
    {
      "epoch": 0.17071522566418892,
      "grad_norm": 0.5347453355789185,
      "learning_rate": 9.84847360293147e-05,
      "loss": 3.5489,
      "step": 1200
    },
    {
      "epoch": 0.17782836006686345,
      "grad_norm": 0.5520544052124023,
      "learning_rate": 9.816648813652638e-05,
      "loss": 3.6093,
      "step": 1250
    },
    {
      "epoch": 0.184941494469538,
      "grad_norm": 0.6506245732307434,
      "learning_rate": 9.7818543827142e-05,
      "loss": 3.5329,
      "step": 1300
    },
    {
      "epoch": 0.19205462887221253,
      "grad_norm": 0.5563200116157532,
      "learning_rate": 9.744111762166251e-05,
      "loss": 3.5535,
      "step": 1350
    },
    {
      "epoch": 0.19916776327488708,
      "grad_norm": 0.5049837231636047,
      "learning_rate": 9.703444221726528e-05,
      "loss": 3.5906,
      "step": 1400
    },
    {
      "epoch": 0.2062808976775616,
      "grad_norm": 0.5633469223976135,
      "learning_rate": 9.659876834433766e-05,
      "loss": 3.5581,
      "step": 1450
    },
    {
      "epoch": 0.21339403208023616,
      "grad_norm": 0.534939169883728,
      "learning_rate": 9.613436461189247e-05,
      "loss": 3.5215,
      "step": 1500
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 0.5206310153007507,
      "learning_rate": 9.56415173419607e-05,
      "loss": 3.6233,
      "step": 1550
    },
    {
      "epoch": 0.22762030088558524,
      "grad_norm": 0.6107692122459412,
      "learning_rate": 9.512053039306333e-05,
      "loss": 3.699,
      "step": 1600
    },
    {
      "epoch": 0.23473343528825977,
      "grad_norm": 0.6045666933059692,
      "learning_rate": 9.457172497287135e-05,
      "loss": 3.6033,
      "step": 1650
    },
    {
      "epoch": 0.24184656969093432,
      "grad_norm": 0.5975181460380554,
      "learning_rate": 9.399543944016948e-05,
      "loss": 3.6722,
      "step": 1700
    },
    {
      "epoch": 0.24895970409360885,
      "grad_norm": 0.6112938523292542,
      "learning_rate": 9.339202909624538e-05,
      "loss": 3.6598,
      "step": 1750
    },
    {
      "epoch": 0.2560728384962834,
      "grad_norm": 0.6086533069610596,
      "learning_rate": 9.276186596583334e-05,
      "loss": 3.5657,
      "step": 1800
    },
    {
      "epoch": 0.2631859728989579,
      "grad_norm": 0.6110842823982239,
      "learning_rate": 9.210533856774735e-05,
      "loss": 3.5513,
      "step": 1850
    },
    {
      "epoch": 0.2702991073016325,
      "grad_norm": 0.6537244915962219,
      "learning_rate": 9.142285167534485e-05,
      "loss": 3.5247,
      "step": 1900
    },
    {
      "epoch": 0.277412241704307,
      "grad_norm": 0.590893030166626,
      "learning_rate": 9.071482606696914e-05,
      "loss": 3.5938,
      "step": 1950
    },
    {
      "epoch": 0.28452537610698153,
      "grad_norm": 0.5756726264953613,
      "learning_rate": 8.998169826652383e-05,
      "loss": 3.604,
      "step": 2000
    },
    {
      "epoch": 0.29163851050965606,
      "grad_norm": 0.6584416031837463,
      "learning_rate": 8.922392027433994e-05,
      "loss": 3.6487,
      "step": 2050
    },
    {
      "epoch": 0.29875164491233064,
      "grad_norm": 0.6359266042709351,
      "learning_rate": 8.844195928850088e-05,
      "loss": 3.5802,
      "step": 2100
    },
    {
      "epoch": 0.30586477931500516,
      "grad_norm": 0.535068929195404,
      "learning_rate": 8.763629741679769e-05,
      "loss": 3.53,
      "step": 2150
    },
    {
      "epoch": 0.3129779137176797,
      "grad_norm": 0.5998860597610474,
      "learning_rate": 8.680743137949176e-05,
      "loss": 3.5816,
      "step": 2200
    },
    {
      "epoch": 0.3200910481203542,
      "grad_norm": 0.5760480165481567,
      "learning_rate": 8.59558722030685e-05,
      "loss": 3.5144,
      "step": 2250
    },
    {
      "epoch": 0.3272041825230288,
      "grad_norm": 0.675940752029419,
      "learning_rate": 8.508214490517064e-05,
      "loss": 3.5398,
      "step": 2300
    },
    {
      "epoch": 0.3343173169257033,
      "grad_norm": 0.6036099791526794,
      "learning_rate": 8.418678817090542e-05,
      "loss": 3.5881,
      "step": 2350
    },
    {
      "epoch": 0.34143045132837785,
      "grad_norm": 0.571083664894104,
      "learning_rate": 8.32703540207255e-05,
      "loss": 3.5668,
      "step": 2400
    },
    {
      "epoch": 0.3485435857310524,
      "grad_norm": 0.6859234571456909,
      "learning_rate": 8.23334074700879e-05,
      "loss": 3.6365,
      "step": 2450
    },
    {
      "epoch": 0.3556567201337269,
      "grad_norm": 0.6588773131370544,
      "learning_rate": 8.137652618110109e-05,
      "loss": 3.5643,
      "step": 2500
    },
    {
      "epoch": 0.3627698545364015,
      "grad_norm": 0.6249911785125732,
      "learning_rate": 8.040030010637508e-05,
      "loss": 3.5468,
      "step": 2550
    },
    {
      "epoch": 0.369882988939076,
      "grad_norm": 0.7182365655899048,
      "learning_rate": 7.940533112529383e-05,
      "loss": 3.5991,
      "step": 2600
    },
    {
      "epoch": 0.37699612334175053,
      "grad_norm": 0.6047330498695374,
      "learning_rate": 7.83922326729344e-05,
      "loss": 3.5994,
      "step": 2650
    },
    {
      "epoch": 0.38410925774442506,
      "grad_norm": 0.6273854970932007,
      "learning_rate": 7.736162936186166e-05,
      "loss": 3.607,
      "step": 2700
    },
    {
      "epoch": 0.39122239214709964,
      "grad_norm": 0.6126185059547424,
      "learning_rate": 7.631415659703149e-05,
      "loss": 3.5323,
      "step": 2750
    },
    {
      "epoch": 0.39833552654977417,
      "grad_norm": 0.6317702531814575,
      "learning_rate": 7.52504601840403e-05,
      "loss": 3.5796,
      "step": 2800
    },
    {
      "epoch": 0.4054486609524487,
      "grad_norm": 0.6616275310516357,
      "learning_rate": 7.417119593096198e-05,
      "loss": 3.553,
      "step": 2850
    },
    {
      "epoch": 0.4125617953551232,
      "grad_norm": 0.6631402969360352,
      "learning_rate": 7.307702924401813e-05,
      "loss": 3.5261,
      "step": 2900
    },
    {
      "epoch": 0.4196749297577978,
      "grad_norm": 0.6131388545036316,
      "learning_rate": 7.196863471733042e-05,
      "loss": 3.6095,
      "step": 2950
    },
    {
      "epoch": 0.4267880641604723,
      "grad_norm": 0.6076405644416809,
      "learning_rate": 7.084669571700864e-05,
      "loss": 3.5785,
      "step": 3000
    },
    {
      "epoch": 0.43390119856314685,
      "grad_norm": 0.7138341069221497,
      "learning_rate": 6.97119039598301e-05,
      "loss": 3.6155,
      "step": 3050
    },
    {
      "epoch": 0.4410143329658214,
      "grad_norm": 0.635661244392395,
      "learning_rate": 6.856495908677078e-05,
      "loss": 3.5415,
      "step": 3100
    },
    {
      "epoch": 0.4481274673684959,
      "grad_norm": 0.6842445731163025,
      "learning_rate": 6.740656823165093e-05,
      "loss": 3.5997,
      "step": 3150
    },
    {
      "epoch": 0.4552406017711705,
      "grad_norm": 0.5924544334411621,
      "learning_rate": 6.623744558516091e-05,
      "loss": 3.5221,
      "step": 3200
    },
    {
      "epoch": 0.462353736173845,
      "grad_norm": 0.6000726222991943,
      "learning_rate": 6.505831195453635e-05,
      "loss": 3.5427,
      "step": 3250
    },
    {
      "epoch": 0.46946687057651953,
      "grad_norm": 0.6143239736557007,
      "learning_rate": 6.38698943191538e-05,
      "loss": 3.5035,
      "step": 3300
    },
    {
      "epoch": 0.47658000497919406,
      "grad_norm": 0.654701828956604,
      "learning_rate": 6.26729253823212e-05,
      "loss": 3.6575,
      "step": 3350
    },
    {
      "epoch": 0.48369313938186864,
      "grad_norm": 0.6718776226043701,
      "learning_rate": 6.14681431195393e-05,
      "loss": 3.5558,
      "step": 3400
    },
    {
      "epoch": 0.49080627378454317,
      "grad_norm": 0.5945755839347839,
      "learning_rate": 6.025629032351248e-05,
      "loss": 3.5268,
      "step": 3450
    },
    {
      "epoch": 0.4979194081872177,
      "grad_norm": 0.6312276721000671,
      "learning_rate": 5.903811414618964e-05,
      "loss": 3.5304,
      "step": 3500
    },
    {
      "epoch": 0.5050325425898923,
      "grad_norm": 0.6054428815841675,
      "learning_rate": 5.781436563811752e-05,
      "loss": 3.6546,
      "step": 3550
    },
    {
      "epoch": 0.5121456769925667,
      "grad_norm": 0.6619254946708679,
      "learning_rate": 5.6585799285390296e-05,
      "loss": 3.5499,
      "step": 3600
    },
    {
      "epoch": 0.5192588113952413,
      "grad_norm": 0.6468092203140259,
      "learning_rate": 5.5353172544481114e-05,
      "loss": 3.5962,
      "step": 3650
    },
    {
      "epoch": 0.5263719457979158,
      "grad_norm": 0.5732932090759277,
      "learning_rate": 5.411724537524214e-05,
      "loss": 3.6242,
      "step": 3700
    },
    {
      "epoch": 0.5334850802005904,
      "grad_norm": 0.6168305277824402,
      "learning_rate": 5.287877977236142e-05,
      "loss": 3.5987,
      "step": 3750
    },
    {
      "epoch": 0.540598214603265,
      "grad_norm": 0.666536271572113,
      "learning_rate": 5.16385392955649e-05,
      "loss": 3.5605,
      "step": 3800
    },
    {
      "epoch": 0.5477113490059394,
      "grad_norm": 0.6101940274238586,
      "learning_rate": 5.0397288598853845e-05,
      "loss": 3.5512,
      "step": 3850
    },
    {
      "epoch": 0.554824483408614,
      "grad_norm": 0.6921783685684204,
      "learning_rate": 4.915579295906726e-05,
      "loss": 3.5575,
      "step": 3900
    },
    {
      "epoch": 0.5619376178112886,
      "grad_norm": 0.807971715927124,
      "learning_rate": 4.791481780406068e-05,
      "loss": 3.5555,
      "step": 3950
    },
    {
      "epoch": 0.5690507522139631,
      "grad_norm": 0.6527642011642456,
      "learning_rate": 4.6675128240791524e-05,
      "loss": 3.5877,
      "step": 4000
    },
    {
      "epoch": 0.5761638866166376,
      "grad_norm": 0.6745109558105469,
      "learning_rate": 4.5437488583602516e-05,
      "loss": 3.5755,
      "step": 4050
    },
    {
      "epoch": 0.5832770210193121,
      "grad_norm": 1.7427842617034912,
      "learning_rate": 4.420266188299362e-05,
      "loss": 3.5694,
      "step": 4100
    },
    {
      "epoch": 0.5903901554219867,
      "grad_norm": 0.6792184710502625,
      "learning_rate": 4.2971409455173386e-05,
      "loss": 3.5766,
      "step": 4150
    },
    {
      "epoch": 0.5975032898246613,
      "grad_norm": 0.6135227084159851,
      "learning_rate": 4.174449041267928e-05,
      "loss": 3.5876,
      "step": 4200
    },
    {
      "epoch": 0.6046164242273357,
      "grad_norm": 0.6110137104988098,
      "learning_rate": 4.0522661196356885e-05,
      "loss": 3.5572,
      "step": 4250
    },
    {
      "epoch": 0.6117295586300103,
      "grad_norm": 0.658260703086853,
      "learning_rate": 3.930667510898627e-05,
      "loss": 3.5892,
      "step": 4300
    },
    {
      "epoch": 0.6188426930326848,
      "grad_norm": 0.7130962610244751,
      "learning_rate": 3.80972818508429e-05,
      "loss": 3.6008,
      "step": 4350
    },
    {
      "epoch": 0.6259558274353594,
      "grad_norm": 0.7225232124328613,
      "learning_rate": 3.6895227057479865e-05,
      "loss": 3.5453,
      "step": 4400
    },
    {
      "epoch": 0.633068961838034,
      "grad_norm": 0.663033127784729,
      "learning_rate": 3.570125184001605e-05,
      "loss": 3.5747,
      "step": 4450
    },
    {
      "epoch": 0.6401820962407084,
      "grad_norm": 0.6274808049201965,
      "learning_rate": 3.451609232821376e-05,
      "loss": 3.5885,
      "step": 4500
    },
    {
      "epoch": 0.647295230643383,
      "grad_norm": 0.6857262849807739,
      "learning_rate": 3.3340479216627585e-05,
      "loss": 3.5575,
      "step": 4550
    },
    {
      "epoch": 0.6544083650460576,
      "grad_norm": 0.6902329325675964,
      "learning_rate": 3.217513731410426e-05,
      "loss": 3.5033,
      "step": 4600
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 0.701437771320343,
      "learning_rate": 3.1020785096911254e-05,
      "loss": 3.5828,
      "step": 4650
    },
    {
      "epoch": 0.6686346338514066,
      "grad_norm": 0.6787740588188171,
      "learning_rate": 2.987813426576972e-05,
      "loss": 3.5622,
      "step": 4700
    },
    {
      "epoch": 0.6757477682540811,
      "grad_norm": 0.6930802464485168,
      "learning_rate": 2.8747889307064625e-05,
      "loss": 3.5761,
      "step": 4750
    },
    {
      "epoch": 0.6828609026567557,
      "grad_norm": 0.7681436538696289,
      "learning_rate": 2.7630747058503015e-05,
      "loss": 3.4808,
      "step": 4800
    },
    {
      "epoch": 0.6899740370594303,
      "grad_norm": 0.7556804418563843,
      "learning_rate": 2.6527396279487827e-05,
      "loss": 3.5065,
      "step": 4850
    },
    {
      "epoch": 0.6970871714621047,
      "grad_norm": 0.8936747312545776,
      "learning_rate": 2.5438517226472314e-05,
      "loss": 3.5317,
      "step": 4900
    },
    {
      "epoch": 0.7042003058647793,
      "grad_norm": 0.678188145160675,
      "learning_rate": 2.436478123355684e-05,
      "loss": 3.5171,
      "step": 4950
    },
    {
      "epoch": 0.7113134402674538,
      "grad_norm": 0.6968974471092224,
      "learning_rate": 2.3306850298586675e-05,
      "loss": 3.5415,
      "step": 5000
    },
    {
      "epoch": 0.7184265746701284,
      "grad_norm": 0.6836689710617065,
      "learning_rate": 2.226537667500581e-05,
      "loss": 3.5505,
      "step": 5050
    },
    {
      "epoch": 0.725539709072803,
      "grad_norm": 0.6989316344261169,
      "learning_rate": 2.124100246971887e-05,
      "loss": 3.5564,
      "step": 5100
    },
    {
      "epoch": 0.7326528434754774,
      "grad_norm": 0.7442585825920105,
      "learning_rate": 2.0234359247208207e-05,
      "loss": 3.5062,
      "step": 5150
    },
    {
      "epoch": 0.739765977878152,
      "grad_norm": 0.7102606296539307,
      "learning_rate": 1.9246067640151382e-05,
      "loss": 3.5822,
      "step": 5200
    },
    {
      "epoch": 0.7468791122808266,
      "grad_norm": 0.6928727030754089,
      "learning_rate": 1.827673696677808e-05,
      "loss": 3.5692,
      "step": 5250
    },
    {
      "epoch": 0.7539922466835011,
      "grad_norm": 0.7725110650062561,
      "learning_rate": 1.7326964855202977e-05,
      "loss": 3.596,
      "step": 5300
    },
    {
      "epoch": 0.7611053810861756,
      "grad_norm": 0.6656366586685181,
      "learning_rate": 1.6397336874965968e-05,
      "loss": 3.549,
      "step": 5350
    },
    {
      "epoch": 0.7682185154888501,
      "grad_norm": 0.6856387257575989,
      "learning_rate": 1.5488426176006975e-05,
      "loss": 3.567,
      "step": 5400
    },
    {
      "epoch": 0.7753316498915247,
      "grad_norm": 0.6431595683097839,
      "learning_rate": 1.4600793135297774e-05,
      "loss": 3.5869,
      "step": 5450
    },
    {
      "epoch": 0.7824447842941993,
      "grad_norm": 0.6482799053192139,
      "learning_rate": 1.3734985011349044e-05,
      "loss": 3.5542,
      "step": 5500
    },
    {
      "epoch": 0.7895579186968738,
      "grad_norm": 0.6933925747871399,
      "learning_rate": 1.289153560680525e-05,
      "loss": 3.5042,
      "step": 5550
    },
    {
      "epoch": 0.7966710530995483,
      "grad_norm": 0.7084000706672668,
      "learning_rate": 1.2070964939335549e-05,
      "loss": 3.5592,
      "step": 5600
    },
    {
      "epoch": 0.8037841875022228,
      "grad_norm": 0.6996510624885559,
      "learning_rate": 1.1273778921023925e-05,
      "loss": 3.5579,
      "step": 5650
    },
    {
      "epoch": 0.8108973219048974,
      "grad_norm": 0.6570999622344971,
      "learning_rate": 1.0500469046455452e-05,
      "loss": 3.5797,
      "step": 5700
    },
    {
      "epoch": 0.818010456307572,
      "grad_norm": 0.6358299255371094,
      "learning_rate": 9.751512089692016e-06,
      "loss": 3.5097,
      "step": 5750
    },
    {
      "epoch": 0.8251235907102464,
      "grad_norm": 0.6734643578529358,
      "learning_rate": 9.027369810323305e-06,
      "loss": 3.4815,
      "step": 5800
    },
    {
      "epoch": 0.832236725112921,
      "grad_norm": 0.6729630827903748,
      "learning_rate": 8.328488668775142e-06,
      "loss": 3.5318,
      "step": 5850
    },
    {
      "epoch": 0.8393498595155956,
      "grad_norm": 0.6969552040100098,
      "learning_rate": 7.655299551050088e-06,
      "loss": 3.5509,
      "step": 5900
    },
    {
      "epoch": 0.8464629939182701,
      "grad_norm": 0.6016611456871033,
      "learning_rate": 7.008217503070347e-06,
      "loss": 3.5089,
      "step": 5950
    },
    {
      "epoch": 0.8535761283209446,
      "grad_norm": 0.661946177482605,
      "learning_rate": 6.387641474786627e-06,
      "loss": 3.6093,
      "step": 6000
    },
    {
      "epoch": 0.8606892627236191,
      "grad_norm": 0.692502498626709,
      "learning_rate": 5.793954074210828e-06,
      "loss": 3.5827,
      "step": 6050
    },
    {
      "epoch": 0.8678023971262937,
      "grad_norm": 0.6985003352165222,
      "learning_rate": 5.227521331524038e-06,
      "loss": 3.5467,
      "step": 6100
    },
    {
      "epoch": 0.8749155315289683,
      "grad_norm": 0.6488695740699768,
      "learning_rate": 4.688692473405459e-06,
      "loss": 3.5312,
      "step": 6150
    },
    {
      "epoch": 0.8820286659316428,
      "grad_norm": 0.7560076117515564,
      "learning_rate": 4.17779970772127e-06,
      "loss": 3.6052,
      "step": 6200
    },
    {
      "epoch": 0.8891418003343173,
      "grad_norm": 0.7229774594306946,
      "learning_rate": 3.695158018706174e-06,
      "loss": 3.5153,
      "step": 6250
    },
    {
      "epoch": 0.8962549347369918,
      "grad_norm": 0.7766822576522827,
      "learning_rate": 3.2410649727641183e-06,
      "loss": 3.5788,
      "step": 6300
    },
    {
      "epoch": 0.9033680691396664,
      "grad_norm": 0.6811705231666565,
      "learning_rate": 2.81580053500749e-06,
      "loss": 3.5878,
      "step": 6350
    },
    {
      "epoch": 0.910481203542341,
      "grad_norm": 0.7530385851860046,
      "learning_rate": 2.4196268966483917e-06,
      "loss": 3.5331,
      "step": 6400
    },
    {
      "epoch": 0.9175943379450154,
      "grad_norm": 0.6751040816307068,
      "learning_rate": 2.052788313348064e-06,
      "loss": 3.566,
      "step": 6450
    },
    {
      "epoch": 0.92470747234769,
      "grad_norm": 0.7490362524986267,
      "learning_rate": 1.7155109546242498e-06,
      "loss": 3.5506,
      "step": 6500
    },
    {
      "epoch": 0.9318206067503646,
      "grad_norm": 0.6602529883384705,
      "learning_rate": 1.4080027644093441e-06,
      "loss": 3.5805,
      "step": 6550
    },
    {
      "epoch": 0.9389337411530391,
      "grad_norm": 0.6192860007286072,
      "learning_rate": 1.1304533328453104e-06,
      "loss": 3.5611,
      "step": 6600
    },
    {
      "epoch": 0.9460468755557137,
      "grad_norm": 0.5917626023292542,
      "learning_rate": 8.830337793943378e-07,
      "loss": 3.5092,
      "step": 6650
    },
    {
      "epoch": 0.9531600099583881,
      "grad_norm": 0.8386017680168152,
      "learning_rate": 6.658966473373939e-07,
      "loss": 3.5512,
      "step": 6700
    },
    {
      "epoch": 0.9602731443610627,
      "grad_norm": 0.7796204090118408,
      "learning_rate": 4.791758097256849e-07,
      "loss": 3.5558,
      "step": 6750
    },
    {
      "epoch": 0.9673862787637373,
      "grad_norm": 0.7370719313621521,
      "learning_rate": 3.229863868429328e-07,
      "loss": 3.5303,
      "step": 6800
    },
    {
      "epoch": 0.9744994131664118,
      "grad_norm": 0.6642888188362122,
      "learning_rate": 1.974246752295239e-07,
      "loss": 3.5825,
      "step": 6850
    },
    {
      "epoch": 0.9816125475690863,
      "grad_norm": 0.8887303471565247,
      "learning_rate": 1.0256808831212162e-07,
      "loss": 3.5752,
      "step": 6900
    },
    {
      "epoch": 0.9887256819717608,
      "grad_norm": 0.6482702493667603,
      "learning_rate": 3.847510867540649e-08,
      "loss": 3.5805,
      "step": 6950
    },
    {
      "epoch": 0.9958388163744354,
      "grad_norm": 0.6639435887336731,
      "learning_rate": 5.185252005457386e-09,
      "loss": 3.5307,
      "step": 7000
    },
    {
      "epoch": 0.9999644343279867,
      "eval_loss": 0.887311577796936,
      "eval_runtime": 1085.9508,
      "eval_samples_per_second": 23.015,
      "eval_steps_per_second": 2.878,
      "step": 7029
    }
  ],
  "logging_steps": 50,
  "max_steps": 7029,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.463854161256317e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
