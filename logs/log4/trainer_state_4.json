{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999644343279867,
  "eval_steps": 500,
  "global_step": 7029,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007113134402674539,
      "grad_norm": 1.871700644493103,
      "learning_rate": 7.112375533428166e-06,
      "loss": 8.3686,
      "step": 50
    },
    {
      "epoch": 0.014226268805349078,
      "grad_norm": 1.2549774646759033,
      "learning_rate": 1.4224751066856332e-05,
      "loss": 7.9564,
      "step": 100
    },
    {
      "epoch": 0.021339403208023616,
      "grad_norm": 2.416856050491333,
      "learning_rate": 2.1337126600284495e-05,
      "loss": 7.1328,
      "step": 150
    },
    {
      "epoch": 0.028452537610698155,
      "grad_norm": 1.18927800655365,
      "learning_rate": 2.8449502133712663e-05,
      "loss": 5.2598,
      "step": 200
    },
    {
      "epoch": 0.03556567201337269,
      "grad_norm": 0.5703340172767639,
      "learning_rate": 3.556187766714083e-05,
      "loss": 3.915,
      "step": 250
    },
    {
      "epoch": 0.04267880641604723,
      "grad_norm": 0.5584468841552734,
      "learning_rate": 4.267425320056899e-05,
      "loss": 3.7965,
      "step": 300
    },
    {
      "epoch": 0.04979194081872177,
      "grad_norm": 0.536492645740509,
      "learning_rate": 4.978662873399716e-05,
      "loss": 3.6595,
      "step": 350
    },
    {
      "epoch": 0.05690507522139631,
      "grad_norm": 0.5239914655685425,
      "learning_rate": 5.6899004267425326e-05,
      "loss": 3.6715,
      "step": 400
    },
    {
      "epoch": 0.06401820962407084,
      "grad_norm": 0.5328537821769714,
      "learning_rate": 6.40113798008535e-05,
      "loss": 3.648,
      "step": 450
    },
    {
      "epoch": 0.07113134402674538,
      "grad_norm": 0.6747919917106628,
      "learning_rate": 7.112375533428166e-05,
      "loss": 3.6749,
      "step": 500
    },
    {
      "epoch": 0.07824447842941992,
      "grad_norm": 0.6069645285606384,
      "learning_rate": 7.823613086770982e-05,
      "loss": 3.6706,
      "step": 550
    },
    {
      "epoch": 0.08535761283209446,
      "grad_norm": 0.5583714246749878,
      "learning_rate": 8.534850640113798e-05,
      "loss": 3.5645,
      "step": 600
    },
    {
      "epoch": 0.092470747234769,
      "grad_norm": 0.528653085231781,
      "learning_rate": 9.246088193456614e-05,
      "loss": 3.677,
      "step": 650
    },
    {
      "epoch": 0.09958388163744354,
      "grad_norm": 0.763389527797699,
      "learning_rate": 9.957325746799432e-05,
      "loss": 3.6695,
      "step": 700
    },
    {
      "epoch": 0.10669701604011808,
      "grad_norm": 0.661715567111969,
      "learning_rate": 9.998638061873831e-05,
      "loss": 3.5758,
      "step": 750
    },
    {
      "epoch": 0.11381015044279262,
      "grad_norm": 0.5684193968772888,
      "learning_rate": 9.994199828119764e-05,
      "loss": 3.5744,
      "step": 800
    },
    {
      "epoch": 0.12092328484546716,
      "grad_norm": 0.5511744022369385,
      "learning_rate": 9.986682485956562e-05,
      "loss": 3.5884,
      "step": 850
    },
    {
      "epoch": 0.1280364192481417,
      "grad_norm": 0.5470666885375977,
      "learning_rate": 9.976090670102949e-05,
      "loss": 3.5949,
      "step": 900
    },
    {
      "epoch": 0.13514955365081624,
      "grad_norm": 0.5619369149208069,
      "learning_rate": 9.962430910804087e-05,
      "loss": 3.5969,
      "step": 950
    },
    {
      "epoch": 0.14226268805349077,
      "grad_norm": 0.6071786284446716,
      "learning_rate": 9.945711629805438e-05,
      "loss": 3.5706,
      "step": 1000
    },
    {
      "epoch": 0.14937582245616532,
      "grad_norm": 0.4760380685329437,
      "learning_rate": 9.925943135160438e-05,
      "loss": 3.5647,
      "step": 1050
    },
    {
      "epoch": 0.15648895685883984,
      "grad_norm": 0.568259060382843,
      "learning_rate": 9.903137614875215e-05,
      "loss": 3.5582,
      "step": 1100
    },
    {
      "epoch": 0.1636020912615144,
      "grad_norm": 0.5963746309280396,
      "learning_rate": 9.877309129394225e-05,
      "loss": 3.6055,
      "step": 1150
    },
    {
      "epoch": 0.17071522566418892,
      "grad_norm": 0.540287435054779,
      "learning_rate": 9.84847360293147e-05,
      "loss": 3.5474,
      "step": 1200
    },
    {
      "epoch": 0.17782836006686345,
      "grad_norm": 0.5485973954200745,
      "learning_rate": 9.816648813652638e-05,
      "loss": 3.6088,
      "step": 1250
    },
    {
      "epoch": 0.184941494469538,
      "grad_norm": 0.6579681634902954,
      "learning_rate": 9.7818543827142e-05,
      "loss": 3.5315,
      "step": 1300
    },
    {
      "epoch": 0.19205462887221253,
      "grad_norm": 0.5505731701850891,
      "learning_rate": 9.744111762166251e-05,
      "loss": 3.5526,
      "step": 1350
    },
    {
      "epoch": 0.19916776327488708,
      "grad_norm": 0.5072546601295471,
      "learning_rate": 9.703444221726528e-05,
      "loss": 3.5897,
      "step": 1400
    },
    {
      "epoch": 0.2062808976775616,
      "grad_norm": 0.5555570721626282,
      "learning_rate": 9.659876834433766e-05,
      "loss": 3.5571,
      "step": 1450
    },
    {
      "epoch": 0.21339403208023616,
      "grad_norm": 0.5338292121887207,
      "learning_rate": 9.613436461189247e-05,
      "loss": 3.5196,
      "step": 1500
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 0.5260260105133057,
      "learning_rate": 9.56415173419607e-05,
      "loss": 3.6212,
      "step": 1550
    },
    {
      "epoch": 0.22762030088558524,
      "grad_norm": 0.5873719453811646,
      "learning_rate": 9.512053039306333e-05,
      "loss": 3.6971,
      "step": 1600
    },
    {
      "epoch": 0.23473343528825977,
      "grad_norm": 0.601745069026947,
      "learning_rate": 9.457172497287135e-05,
      "loss": 3.6019,
      "step": 1650
    },
    {
      "epoch": 0.24184656969093432,
      "grad_norm": 0.5995392203330994,
      "learning_rate": 9.399543944016948e-05,
      "loss": 3.6717,
      "step": 1700
    },
    {
      "epoch": 0.24895970409360885,
      "grad_norm": 0.6069818139076233,
      "learning_rate": 9.339202909624538e-05,
      "loss": 3.6585,
      "step": 1750
    },
    {
      "epoch": 0.2560728384962834,
      "grad_norm": 0.6007643938064575,
      "learning_rate": 9.276186596583334e-05,
      "loss": 3.5655,
      "step": 1800
    },
    {
      "epoch": 0.2631859728989579,
      "grad_norm": 0.6007878184318542,
      "learning_rate": 9.210533856774735e-05,
      "loss": 3.5503,
      "step": 1850
    },
    {
      "epoch": 0.2702991073016325,
      "grad_norm": 0.6540079712867737,
      "learning_rate": 9.142285167534485e-05,
      "loss": 3.5246,
      "step": 1900
    },
    {
      "epoch": 0.277412241704307,
      "grad_norm": 0.5827665328979492,
      "learning_rate": 9.071482606696914e-05,
      "loss": 3.5926,
      "step": 1950
    },
    {
      "epoch": 0.28452537610698153,
      "grad_norm": 0.5773646831512451,
      "learning_rate": 8.998169826652383e-05,
      "loss": 3.6033,
      "step": 2000
    },
    {
      "epoch": 0.29163851050965606,
      "grad_norm": 0.651374340057373,
      "learning_rate": 8.922392027433994e-05,
      "loss": 3.6478,
      "step": 2050
    },
    {
      "epoch": 0.29875164491233064,
      "grad_norm": 0.6431915760040283,
      "learning_rate": 8.844195928850088e-05,
      "loss": 3.5793,
      "step": 2100
    },
    {
      "epoch": 0.30586477931500516,
      "grad_norm": 0.5357694029808044,
      "learning_rate": 8.763629741679769e-05,
      "loss": 3.5296,
      "step": 2150
    },
    {
      "epoch": 0.3129779137176797,
      "grad_norm": 0.6088343262672424,
      "learning_rate": 8.680743137949176e-05,
      "loss": 3.5808,
      "step": 2200
    },
    {
      "epoch": 0.3200910481203542,
      "grad_norm": 0.5686312317848206,
      "learning_rate": 8.59558722030685e-05,
      "loss": 3.5139,
      "step": 2250
    },
    {
      "epoch": 0.3272041825230288,
      "grad_norm": 0.6084087491035461,
      "learning_rate": 8.508214490517064e-05,
      "loss": 3.5386,
      "step": 2300
    },
    {
      "epoch": 0.3343173169257033,
      "grad_norm": 0.5924165844917297,
      "learning_rate": 8.418678817090542e-05,
      "loss": 3.588,
      "step": 2350
    },
    {
      "epoch": 0.34143045132837785,
      "grad_norm": 0.5698533058166504,
      "learning_rate": 8.32703540207255e-05,
      "loss": 3.5669,
      "step": 2400
    },
    {
      "epoch": 0.3485435857310524,
      "grad_norm": 0.6854032874107361,
      "learning_rate": 8.23334074700879e-05,
      "loss": 3.6357,
      "step": 2450
    },
    {
      "epoch": 0.3556567201337269,
      "grad_norm": 0.6606762409210205,
      "learning_rate": 8.137652618110109e-05,
      "loss": 3.564,
      "step": 2500
    },
    {
      "epoch": 0.3627698545364015,
      "grad_norm": 0.6282462477684021,
      "learning_rate": 8.040030010637508e-05,
      "loss": 3.546,
      "step": 2550
    },
    {
      "epoch": 0.369882988939076,
      "grad_norm": 0.7103673219680786,
      "learning_rate": 7.940533112529383e-05,
      "loss": 3.5976,
      "step": 2600
    },
    {
      "epoch": 0.37699612334175053,
      "grad_norm": 0.6024754047393799,
      "learning_rate": 7.83922326729344e-05,
      "loss": 3.5989,
      "step": 2650
    },
    {
      "epoch": 0.38410925774442506,
      "grad_norm": 0.6123910546302795,
      "learning_rate": 7.736162936186166e-05,
      "loss": 3.6061,
      "step": 2700
    },
    {
      "epoch": 0.39122239214709964,
      "grad_norm": 0.612362265586853,
      "learning_rate": 7.631415659703149e-05,
      "loss": 3.5317,
      "step": 2750
    },
    {
      "epoch": 0.39833552654977417,
      "grad_norm": 0.6282133460044861,
      "learning_rate": 7.52504601840403e-05,
      "loss": 3.5798,
      "step": 2800
    },
    {
      "epoch": 0.4054486609524487,
      "grad_norm": 0.6636735200881958,
      "learning_rate": 7.417119593096198e-05,
      "loss": 3.5519,
      "step": 2850
    },
    {
      "epoch": 0.4125617953551232,
      "grad_norm": 0.6574362516403198,
      "learning_rate": 7.307702924401813e-05,
      "loss": 3.525,
      "step": 2900
    },
    {
      "epoch": 0.4196749297577978,
      "grad_norm": 0.6177923679351807,
      "learning_rate": 7.196863471733042e-05,
      "loss": 3.609,
      "step": 2950
    },
    {
      "epoch": 0.4267880641604723,
      "grad_norm": 0.6130422353744507,
      "learning_rate": 7.084669571700864e-05,
      "loss": 3.5776,
      "step": 3000
    },
    {
      "epoch": 0.43390119856314685,
      "grad_norm": 0.7063397765159607,
      "learning_rate": 6.97119039598301e-05,
      "loss": 3.615,
      "step": 3050
    },
    {
      "epoch": 0.4410143329658214,
      "grad_norm": 0.6230066418647766,
      "learning_rate": 6.856495908677078e-05,
      "loss": 3.5412,
      "step": 3100
    },
    {
      "epoch": 0.4481274673684959,
      "grad_norm": 0.6787882447242737,
      "learning_rate": 6.740656823165093e-05,
      "loss": 3.5986,
      "step": 3150
    },
    {
      "epoch": 0.4552406017711705,
      "grad_norm": 0.6041738390922546,
      "learning_rate": 6.623744558516091e-05,
      "loss": 3.5216,
      "step": 3200
    },
    {
      "epoch": 0.462353736173845,
      "grad_norm": 0.5952249765396118,
      "learning_rate": 6.505831195453635e-05,
      "loss": 3.542,
      "step": 3250
    },
    {
      "epoch": 0.46946687057651953,
      "grad_norm": 0.6119939088821411,
      "learning_rate": 6.38698943191538e-05,
      "loss": 3.5029,
      "step": 3300
    },
    {
      "epoch": 0.47658000497919406,
      "grad_norm": 0.6453254222869873,
      "learning_rate": 6.26729253823212e-05,
      "loss": 3.6573,
      "step": 3350
    },
    {
      "epoch": 0.48369313938186864,
      "grad_norm": 0.662621259689331,
      "learning_rate": 6.14681431195393e-05,
      "loss": 3.5557,
      "step": 3400
    },
    {
      "epoch": 0.49080627378454317,
      "grad_norm": 0.5916626453399658,
      "learning_rate": 6.025629032351248e-05,
      "loss": 3.5261,
      "step": 3450
    },
    {
      "epoch": 0.4979194081872177,
      "grad_norm": 0.6230077147483826,
      "learning_rate": 5.903811414618964e-05,
      "loss": 3.5293,
      "step": 3500
    },
    {
      "epoch": 0.5050325425898923,
      "grad_norm": 0.6071013808250427,
      "learning_rate": 5.781436563811752e-05,
      "loss": 3.6527,
      "step": 3550
    },
    {
      "epoch": 0.5121456769925667,
      "grad_norm": 0.6627265810966492,
      "learning_rate": 5.6585799285390296e-05,
      "loss": 3.549,
      "step": 3600
    },
    {
      "epoch": 0.5192588113952413,
      "grad_norm": 0.6543785333633423,
      "learning_rate": 5.5353172544481114e-05,
      "loss": 3.5955,
      "step": 3650
    },
    {
      "epoch": 0.5263719457979158,
      "grad_norm": 0.5789597034454346,
      "learning_rate": 5.411724537524214e-05,
      "loss": 3.6234,
      "step": 3700
    },
    {
      "epoch": 0.5334850802005904,
      "grad_norm": 0.6165706515312195,
      "learning_rate": 5.287877977236142e-05,
      "loss": 3.5973,
      "step": 3750
    },
    {
      "epoch": 0.540598214603265,
      "grad_norm": 0.6654433608055115,
      "learning_rate": 5.16385392955649e-05,
      "loss": 3.5602,
      "step": 3800
    },
    {
      "epoch": 0.5477113490059394,
      "grad_norm": 0.6083391308784485,
      "learning_rate": 5.0397288598853845e-05,
      "loss": 3.551,
      "step": 3850
    },
    {
      "epoch": 0.554824483408614,
      "grad_norm": 0.6846528649330139,
      "learning_rate": 4.915579295906726e-05,
      "loss": 3.5563,
      "step": 3900
    },
    {
      "epoch": 0.5619376178112886,
      "grad_norm": 0.7990697622299194,
      "learning_rate": 4.791481780406068e-05,
      "loss": 3.5555,
      "step": 3950
    },
    {
      "epoch": 0.5690507522139631,
      "grad_norm": 0.645048201084137,
      "learning_rate": 4.6675128240791524e-05,
      "loss": 3.5872,
      "step": 4000
    },
    {
      "epoch": 0.5761638866166376,
      "grad_norm": 0.6658406853675842,
      "learning_rate": 4.5437488583602516e-05,
      "loss": 3.5753,
      "step": 4050
    },
    {
      "epoch": 0.5832770210193121,
      "grad_norm": 0.664888322353363,
      "learning_rate": 4.420266188299362e-05,
      "loss": 3.5694,
      "step": 4100
    },
    {
      "epoch": 0.5903901554219867,
      "grad_norm": 0.6795247197151184,
      "learning_rate": 4.2971409455173386e-05,
      "loss": 3.5772,
      "step": 4150
    },
    {
      "epoch": 0.5975032898246613,
      "grad_norm": 0.6161702871322632,
      "learning_rate": 4.174449041267928e-05,
      "loss": 3.5872,
      "step": 4200
    },
    {
      "epoch": 0.6046164242273357,
      "grad_norm": 0.5980982184410095,
      "learning_rate": 4.0522661196356885e-05,
      "loss": 3.5572,
      "step": 4250
    },
    {
      "epoch": 0.6117295586300103,
      "grad_norm": 0.6506866216659546,
      "learning_rate": 3.930667510898627e-05,
      "loss": 3.5884,
      "step": 4300
    },
    {
      "epoch": 0.6188426930326848,
      "grad_norm": 0.7056805491447449,
      "learning_rate": 3.80972818508429e-05,
      "loss": 3.6001,
      "step": 4350
    },
    {
      "epoch": 0.6259558274353594,
      "grad_norm": 0.7253905534744263,
      "learning_rate": 3.6895227057479865e-05,
      "loss": 3.5454,
      "step": 4400
    },
    {
      "epoch": 0.633068961838034,
      "grad_norm": 0.6614469289779663,
      "learning_rate": 3.570125184001605e-05,
      "loss": 3.5743,
      "step": 4450
    },
    {
      "epoch": 0.6401820962407084,
      "grad_norm": 0.6234169006347656,
      "learning_rate": 3.451609232821376e-05,
      "loss": 3.589,
      "step": 4500
    },
    {
      "epoch": 0.647295230643383,
      "grad_norm": 0.6774606108665466,
      "learning_rate": 3.3340479216627585e-05,
      "loss": 3.5564,
      "step": 4550
    },
    {
      "epoch": 0.6544083650460576,
      "grad_norm": 0.6852203011512756,
      "learning_rate": 3.217513731410426e-05,
      "loss": 3.5026,
      "step": 4600
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 0.6834695935249329,
      "learning_rate": 3.1020785096911254e-05,
      "loss": 3.5818,
      "step": 4650
    },
    {
      "epoch": 0.6686346338514066,
      "grad_norm": 0.6655176281929016,
      "learning_rate": 2.987813426576972e-05,
      "loss": 3.5628,
      "step": 4700
    },
    {
      "epoch": 0.6757477682540811,
      "grad_norm": 0.6877829432487488,
      "learning_rate": 2.8747889307064625e-05,
      "loss": 3.5746,
      "step": 4750
    },
    {
      "epoch": 0.6828609026567557,
      "grad_norm": 0.7606545090675354,
      "learning_rate": 2.7630747058503015e-05,
      "loss": 3.4806,
      "step": 4800
    },
    {
      "epoch": 0.6899740370594303,
      "grad_norm": 0.7428089380264282,
      "learning_rate": 2.6527396279487827e-05,
      "loss": 3.5057,
      "step": 4850
    },
    {
      "epoch": 0.6970871714621047,
      "grad_norm": 0.7802836894989014,
      "learning_rate": 2.5438517226472314e-05,
      "loss": 3.5315,
      "step": 4900
    },
    {
      "epoch": 0.7042003058647793,
      "grad_norm": 0.675644040107727,
      "learning_rate": 2.436478123355684e-05,
      "loss": 3.5175,
      "step": 4950
    },
    {
      "epoch": 0.7113134402674538,
      "grad_norm": 0.6929371953010559,
      "learning_rate": 2.3306850298586675e-05,
      "loss": 3.541,
      "step": 5000
    },
    {
      "epoch": 0.7184265746701284,
      "grad_norm": 0.6766306161880493,
      "learning_rate": 2.226537667500581e-05,
      "loss": 3.5498,
      "step": 5050
    },
    {
      "epoch": 0.725539709072803,
      "grad_norm": 0.6828836798667908,
      "learning_rate": 2.124100246971887e-05,
      "loss": 3.5561,
      "step": 5100
    },
    {
      "epoch": 0.7326528434754774,
      "grad_norm": 0.7383871078491211,
      "learning_rate": 2.0234359247208207e-05,
      "loss": 3.5063,
      "step": 5150
    },
    {
      "epoch": 0.739765977878152,
      "grad_norm": 0.7041580677032471,
      "learning_rate": 1.9246067640151382e-05,
      "loss": 3.5823,
      "step": 5200
    },
    {
      "epoch": 0.7468791122808266,
      "grad_norm": 0.6929107308387756,
      "learning_rate": 1.827673696677808e-05,
      "loss": 3.5683,
      "step": 5250
    },
    {
      "epoch": 0.7539922466835011,
      "grad_norm": 0.7703820466995239,
      "learning_rate": 1.7326964855202977e-05,
      "loss": 3.5962,
      "step": 5300
    },
    {
      "epoch": 0.7611053810861756,
      "grad_norm": 0.6479637622833252,
      "learning_rate": 1.6397336874965968e-05,
      "loss": 3.5484,
      "step": 5350
    },
    {
      "epoch": 0.7682185154888501,
      "grad_norm": 0.6804231405258179,
      "learning_rate": 1.5488426176006975e-05,
      "loss": 3.5666,
      "step": 5400
    },
    {
      "epoch": 0.7753316498915247,
      "grad_norm": 0.6410537958145142,
      "learning_rate": 1.4600793135297774e-05,
      "loss": 3.5851,
      "step": 5450
    },
    {
      "epoch": 0.7824447842941993,
      "grad_norm": 0.6494694948196411,
      "learning_rate": 1.3734985011349044e-05,
      "loss": 3.555,
      "step": 5500
    },
    {
      "epoch": 0.7895579186968738,
      "grad_norm": 0.6939265131950378,
      "learning_rate": 1.289153560680525e-05,
      "loss": 3.5047,
      "step": 5550
    },
    {
      "epoch": 0.7966710530995483,
      "grad_norm": 0.705957293510437,
      "learning_rate": 1.2070964939335549e-05,
      "loss": 3.5585,
      "step": 5600
    },
    {
      "epoch": 0.8037841875022228,
      "grad_norm": 0.7000975012779236,
      "learning_rate": 1.1273778921023925e-05,
      "loss": 3.5578,
      "step": 5650
    },
    {
      "epoch": 0.8108973219048974,
      "grad_norm": 0.6495917439460754,
      "learning_rate": 1.0500469046455452e-05,
      "loss": 3.5793,
      "step": 5700
    },
    {
      "epoch": 0.818010456307572,
      "grad_norm": 0.6390385627746582,
      "learning_rate": 9.751512089692016e-06,
      "loss": 3.5094,
      "step": 5750
    },
    {
      "epoch": 0.8251235907102464,
      "grad_norm": 0.6665589213371277,
      "learning_rate": 9.027369810323305e-06,
      "loss": 3.482,
      "step": 5800
    },
    {
      "epoch": 0.832236725112921,
      "grad_norm": 0.6713524460792542,
      "learning_rate": 8.328488668775142e-06,
      "loss": 3.5318,
      "step": 5850
    },
    {
      "epoch": 0.8393498595155956,
      "grad_norm": 0.6897595524787903,
      "learning_rate": 7.655299551050088e-06,
      "loss": 3.5504,
      "step": 5900
    },
    {
      "epoch": 0.8464629939182701,
      "grad_norm": 0.5929152369499207,
      "learning_rate": 7.008217503070347e-06,
      "loss": 3.5084,
      "step": 5950
    },
    {
      "epoch": 0.8535761283209446,
      "grad_norm": 0.6452401876449585,
      "learning_rate": 6.387641474786627e-06,
      "loss": 3.6086,
      "step": 6000
    },
    {
      "epoch": 0.8606892627236191,
      "grad_norm": 0.6888181567192078,
      "learning_rate": 5.793954074210828e-06,
      "loss": 3.5817,
      "step": 6050
    },
    {
      "epoch": 0.8678023971262937,
      "grad_norm": 0.6976126432418823,
      "learning_rate": 5.227521331524038e-06,
      "loss": 3.5453,
      "step": 6100
    },
    {
      "epoch": 0.8749155315289683,
      "grad_norm": 0.6493414640426636,
      "learning_rate": 4.688692473405459e-06,
      "loss": 3.5306,
      "step": 6150
    },
    {
      "epoch": 0.8820286659316428,
      "grad_norm": 0.7496370077133179,
      "learning_rate": 4.17779970772127e-06,
      "loss": 3.6059,
      "step": 6200
    },
    {
      "epoch": 0.8891418003343173,
      "grad_norm": 0.7118589878082275,
      "learning_rate": 3.695158018706174e-06,
      "loss": 3.5167,
      "step": 6250
    },
    {
      "epoch": 0.8962549347369918,
      "grad_norm": 0.7683635950088501,
      "learning_rate": 3.2410649727641183e-06,
      "loss": 3.5785,
      "step": 6300
    },
    {
      "epoch": 0.9033680691396664,
      "grad_norm": 0.6594080924987793,
      "learning_rate": 2.81580053500749e-06,
      "loss": 3.5869,
      "step": 6350
    },
    {
      "epoch": 0.910481203542341,
      "grad_norm": 0.7400626540184021,
      "learning_rate": 2.4196268966483917e-06,
      "loss": 3.5312,
      "step": 6400
    },
    {
      "epoch": 0.9175943379450154,
      "grad_norm": 0.6657294631004333,
      "learning_rate": 2.052788313348064e-06,
      "loss": 3.5659,
      "step": 6450
    },
    {
      "epoch": 0.92470747234769,
      "grad_norm": 0.7313651442527771,
      "learning_rate": 1.7155109546242498e-06,
      "loss": 3.5511,
      "step": 6500
    },
    {
      "epoch": 0.9318206067503646,
      "grad_norm": 0.6509383320808411,
      "learning_rate": 1.4080027644093441e-06,
      "loss": 3.5804,
      "step": 6550
    },
    {
      "epoch": 0.9389337411530391,
      "grad_norm": 0.6047760844230652,
      "learning_rate": 1.1304533328453104e-06,
      "loss": 3.5604,
      "step": 6600
    },
    {
      "epoch": 0.9460468755557137,
      "grad_norm": 0.5904654264450073,
      "learning_rate": 8.830337793943378e-07,
      "loss": 3.5084,
      "step": 6650
    },
    {
      "epoch": 0.9531600099583881,
      "grad_norm": 0.8340773582458496,
      "learning_rate": 6.658966473373939e-07,
      "loss": 3.5512,
      "step": 6700
    },
    {
      "epoch": 0.9602731443610627,
      "grad_norm": 0.7203147411346436,
      "learning_rate": 4.791758097256849e-07,
      "loss": 3.5557,
      "step": 6750
    },
    {
      "epoch": 0.9673862787637373,
      "grad_norm": 0.7275068759918213,
      "learning_rate": 3.229863868429328e-07,
      "loss": 3.5296,
      "step": 6800
    },
    {
      "epoch": 0.9744994131664118,
      "grad_norm": 0.6598113179206848,
      "learning_rate": 1.974246752295239e-07,
      "loss": 3.5826,
      "step": 6850
    },
    {
      "epoch": 0.9816125475690863,
      "grad_norm": 0.7193687558174133,
      "learning_rate": 1.0256808831212162e-07,
      "loss": 3.5752,
      "step": 6900
    },
    {
      "epoch": 0.9887256819717608,
      "grad_norm": 0.6443333029747009,
      "learning_rate": 3.847510867540649e-08,
      "loss": 3.5805,
      "step": 6950
    },
    {
      "epoch": 0.9958388163744354,
      "grad_norm": 0.6584141254425049,
      "learning_rate": 5.185252005457386e-09,
      "loss": 3.53,
      "step": 7000
    },
    {
      "epoch": 0.9999644343279867,
      "eval_loss": 0.8871724605560303,
      "eval_runtime": 1096.3968,
      "eval_samples_per_second": 22.796,
      "eval_steps_per_second": 2.85,
      "step": 7029
    }
  ],
  "logging_steps": 50,
  "max_steps": 7029,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.463854161256317e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
